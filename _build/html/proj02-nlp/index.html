<!DOCTYPE html><html lang="en" class="" style="scroll-padding:60px"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width,initial-scale=1"/><title>Project 2: Reproducibility in Natural Language Processing - Stat159 Project 2 - Reproducibility in Natural Language Processing</title><meta property="og:title" content="Project 2: Reproducibility in Natural Language Processing - Stat159 Project 2 - Reproducibility in Natural Language Processing"/><meta name="generator" content="mystmd"/><meta name="keywords" content=""/><meta name="image" content="/user/jcollins36855/myst-build/proj02-group7/build/b77199e99a54e59b2e3c037c2cc90f21.svg"/><meta property="og:image" content="/user/jcollins36855/myst-build/proj02-group7/build/b77199e99a54e59b2e3c037c2cc90f21.svg"/><link rel="stylesheet" href="/user/jcollins36855/myst-build/proj02-group7/build/_assets/app-IZWEOBHI.css"/><link rel="stylesheet" href="/user/jcollins36855/myst-build/proj02-group7/build/_assets/thebe-core-VKVHG5VY.css"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/jupyter-matplotlib@0.11.3/css/mpl_widget.css"/><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.css"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.css" integrity="sha384-MlJdn/WNKDGXveldHDdyRP1R4CTHr3FeuDNfhsLPYrq2t0UBkUdK2jyTnXPEK1NQ" crossorigin="anonymous"/><link rel="icon" href="/user/jcollins36855/myst-build/proj02-group7/favicon.ico"/><link rel="stylesheet" href="/user/jcollins36855/myst-build/proj02-group7/myst-theme.css"/><script>
  const savedTheme = localStorage.getItem("myst:theme");
  const theme = window.matchMedia("(prefers-color-scheme: light)").matches ? 'light' : 'dark';
  const classes = document.documentElement.classList;
  const hasAnyTheme = classes.contains('light') || classes.contains('dark');
  if (!hasAnyTheme) classes.add(savedTheme ?? theme);
</script></head><body class="m-0 transition-colors duration-500 bg-white dark:bg-stone-900"><div class="fixed top-1 left-1 h-[0px] w-[0px] focus-within:z-40 focus-within:h-auto focus-within:w-auto bg-white overflow-hidden focus-within:p-2 focus-within:ring-1" aria-label="skip to content options"><a href="#skip-to-frontmatter" class="block px-2 py-1 text-black underline">Skip to article frontmatter</a><a href="#skip-to-article" class="block px-2 py-1 text-black underline">Skip to article content</a></div><div class="bg-white/80 backdrop-blur dark:bg-stone-900/80 shadow dark:shadow-stone-700 p-3 md:px-8 sticky w-screen top-0 z-30 h-[60px]"><nav class="flex items-center justify-between flex-nowrap max-w-[1440px] mx-auto"><div class="flex flex-row xl:min-w-[19.5rem] mr-2 sm:mr-7 justify-start items-center shrink-0"><div class="block xl:hidden"><button class="flex items-center border-stone-400 text-stone-800 hover:text-stone-900 dark:text-stone-200 hover:dark:text-stone-100"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" width="2rem" height="2rem" class="m-1"><path fill-rule="evenodd" d="M3 6.75A.75.75 0 0 1 3.75 6h16.5a.75.75 0 0 1 0 1.5H3.75A.75.75 0 0 1 3 6.75ZM3 12a.75.75 0 0 1 .75-.75h16.5a.75.75 0 0 1 0 1.5H3.75A.75.75 0 0 1 3 12Zm0 5.25a.75.75 0 0 1 .75-.75h16.5a.75.75 0 0 1 0 1.5H3.75a.75.75 0 0 1-.75-.75Z" clip-rule="evenodd"></path></svg><span class="sr-only">Open Menu</span></button></div><a class="flex items-center ml-3 dark:text-white w-fit md:ml-5 xl:ml-7" href="/user/jcollins36855/myst-build/proj02-group7/"><span class="text-md sm:text-xl tracking-tight sm:mr-5">Made with MyST</span></a></div><div class="flex items-center flex-grow w-auto"><div class="flex-grow hidden text-md lg:block"></div><div class="flex-grow block"></div><button type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-:R74op:" data-state="closed" class="flex items-center h-10 aspect-square sm:w-64 text-left text-gray-400 border border-gray-300 dark:border-gray-600 rounded-lg bg-gray-50 dark:bg-gray-700 hover:ring-blue-500 dark:hover:ring-blue-500 hover:border-blue-500 dark:hover:border-blue-500"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="p-2.5 h-10 w-10 aspect-square"><path fill-rule="evenodd" d="M10.5 3.75a6.75 6.75 0 1 0 0 13.5 6.75 6.75 0 0 0 0-13.5ZM2.25 10.5a8.25 8.25 0 1 1 14.59 5.28l4.69 4.69a.75.75 0 1 1-1.06 1.06l-4.69-4.69A8.25 8.25 0 0 1 2.25 10.5Z" clip-rule="evenodd"></path></svg><span class="hidden sm:block grow">Search</span><div aria-hidden="true" class="items-center hidden mx-1 font-mono text-sm text-gray-400 sm:flex gap-x-1"><kbd class="px-2 py-1 border border-gray-300 dark:border-gray-600 rounded-md shadow-[0px_2px_0px_0px_rgba(0,0,0,0.08)] dark:shadow-none hide-mac">CTRL</kbd><kbd class="px-2 py-1 border border-gray-300 dark:border-gray-600 rounded-md shadow-[0px_2px_0px_0px_rgba(0,0,0,0.08)] dark:shadow-none show-mac">⌘</kbd><kbd class="px-2 py-1 border border-gray-300 dark:border-gray-600 rounded-md shadow-[0px_2px_0px_0px_rgba(0,0,0,0.08)] dark:shadow-none ">K</kbd><script>
;(() => {
const script = document.currentScript;
const root = script.parentElement;

const isMac = /mac/i.test(
      window.navigator.userAgentData?.platform ?? window.navigator.userAgent,
    );
root.querySelectorAll(".hide-mac").forEach(node => {node.classList.add(isMac ? "hidden" : "block")});
root.querySelectorAll(".show-mac").forEach(node => {node.classList.add(!isMac ? "hidden" : "block")});
})()</script></div></button><button class="theme rounded-full aspect-square border border-stone-700 dark:border-white hover:bg-neutral-100 border-solid overflow-hidden text-stone-700 dark:text-white hover:text-stone-500 dark:hover:text-neutral-800 w-8 h-8 mx-3" title="Toggle theme between light and dark mode" aria-label="Toggle theme between light and dark mode"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="h-full w-full p-0.5 hidden dark:block"><path fill-rule="evenodd" d="M9.528 1.718a.75.75 0 0 1 .162.819A8.97 8.97 0 0 0 9 6a9 9 0 0 0 9 9 8.97 8.97 0 0 0 3.463-.69.75.75 0 0 1 .981.98 10.503 10.503 0 0 1-9.694 6.46c-5.799 0-10.5-4.7-10.5-10.5 0-4.368 2.667-8.112 6.46-9.694a.75.75 0 0 1 .818.162Z" clip-rule="evenodd"></path></svg><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-full w-full p-0.5 dark:hidden"><path stroke-linecap="round" stroke-linejoin="round" d="M12 3v2.25m6.364.386-1.591 1.591M21 12h-2.25m-.386 6.364-1.591-1.591M12 18.75V21m-4.773-4.227-1.591 1.591M5.25 12H3m4.227-4.773L5.636 5.636M15.75 12a3.75 3.75 0 1 1-7.5 0 3.75 3.75 0 0 1 7.5 0Z"></path></svg></button><div class="block sm:hidden"></div><div class="hidden sm:block"></div></div></nav></div><div class="fixed xl:article-grid grid-gap xl:w-screen xl:pointer-events-none overflow-auto max-xl:min-w-[300px] hidden z-10" style="top:60px"><div class="pointer-events-auto xl:col-margin-left flex-col overflow-hidden hidden xl:flex"><div class="flex-grow py-6 overflow-y-auto primary-scrollbar"><nav aria-label="Navigation" class="overflow-y-hidden transition-opacity ml-3 xl:ml-0 mr-3 max-w-[350px] lg:hidden"><div class="w-full px-1 dark:text-white font-medium"></div></nav><div class="my-3 border-b-2 lg:hidden"></div><nav aria-label="Table of Contents" class="flex-grow overflow-y-hidden transition-opacity ml-3 xl:ml-0 mr-3 max-w-[350px]"><div class="w-full px-1 dark:text-white"><a title="Stat159 Project 2 - Reproducibility in Natural Language Processing" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30 font-bold" href="/user/jcollins36855/myst-build/proj02-group7/">Stat159 Project 2 - Reproducibility in Natural Language Processing</a><a title="Contributions" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/user/jcollins36855/myst-build/proj02-group7/contributions">Contributions</a><a title="Project 2: Reproducibility in Natural Language Processing" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/user/jcollins36855/myst-build/proj02-group7/nlp-p01">Project 2: Reproducibility in Natural Language Processing</a><a title="Part 2: Simple Text Processing - Tokenization, Lemmatization, Word Frequency, Vectorization (20 pts)" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/user/jcollins36855/myst-build/proj02-group7/nlp-p02">Part 2: Simple Text Processing - Tokenization, Lemmatization, Word Frequency, Vectorization (20 pts)</a><a title="Part 3: Advanced Text Processing - LDA and BERTopic Topic Modeling (20 pts)" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/user/jcollins36855/myst-build/proj02-group7/nlp-p03">Part 3: Advanced Text Processing - LDA and BERTopic Topic Modeling (20 pts)</a><a title="Part 4" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/user/jcollins36855/myst-build/proj02-group7/nlp-p04">Part 4</a><a title="Project 2: Reproducibility in Natural Language Processing" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/user/jcollins36855/myst-build/proj02-group7/proj02-nlp">Project 2: Reproducibility in Natural Language Processing</a><a title="Project 2: Reproducibility in Natural Langauge Processing" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/user/jcollins36855/myst-build/proj02-group7/project-description">Project 2: Reproducibility in Natural Langauge Processing</a></div></nav></div><div class="flex-none py-6 transition-all duration-700 translate-y-6 opacity-0"><a class="flex mx-auto text-gray-700 w-fit hover:text-blue-700 dark:text-gray-200 dark:hover:text-blue-400" href="https://mystmd.org/made-with-myst" target="_blank" rel="noreferrer"><svg style="width:24px;height:24px" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 100 100" stroke="none"><g id="icon"><path fill="currentColor" d="M23.8,54.8v-3.6l4.7-0.8V17.5l-4.7-0.8V13H36l13.4,31.7h0.2l13-31.7h12.6v3.6l-4.7,0.8v32.9l4.7,0.8v3.6h-15
          v-3.6l4.9-0.8V20.8H65L51.4,53.3h-3.8l-14-32.5h-0.1l0.2,17.4v12.1l5,0.8v3.6H23.8z"></path><path fill="#F37726" d="M47,86.9c0-5.9-3.4-8.8-10.1-8.8h-8.4c-5.2,0-9.4-1.3-12.5-3.8c-3.1-2.5-5.4-6.2-6.8-11l4.8-1.6
          c1.8,5.6,6.4,8.6,13.8,8.8h9.2c6.4,0,10.8,2.5,13.1,7.5c2.3-5,6.7-7.5,13.1-7.5h8.4c7.8,0,12.7-2.9,14.6-8.7l4.8,1.6
          c-1.4,4.9-3.6,8.6-6.8,11.1c-3.1,2.5-7.3,3.7-12.4,3.8H63c-6.7,0-10,2.9-10,8.8"></path></g></svg><span class="self-center ml-2 text-sm">Made with MyST</span></a></div></div></div><main class="article-grid grid-gap"><article class="article-grid subgrid-gap col-screen article content"><div class="hidden"></div><div id="skip-to-frontmatter" aria-label="article frontmatter" class="mb-8 pt-9"><div class="flex items-center mb-5 h-6 text-sm font-light"><div class="flex-grow"></div><a href="https://github.com/UCB-stat-159-f25/proj02-group7" title="GitHub Repository: UCB-stat-159-f25/proj02-group7" target="_blank" rel="noopener noreferrer" class="text-inherit hover:text-inherit"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" width="1.25rem" height="1.25rem" class="inline-block mr-1 opacity-60 hover:opacity-100"><path d="M12 2.5c-5.4 0-9.8 4.4-9.8 9.7 0 4.3 2.8 8 6.7 9.2.5.1.7-.2.7-.5v-1.8c-2.4.5-3.1-.6-3.3-1.1-.1-.3-.6-1.1-1-1.4-.3-.2-.8-.6 0-.6s1.3.7 1.5 1c.9 1.5 2.3 1.1 2.8.8.1-.6.3-1.1.6-1.3-2.2-.2-4.4-1.1-4.4-4.8 0-1.1.4-1.9 1-2.6-.1-.2-.4-1.2.1-2.6 0 0 .8-.3 2.7 1 .8-.2 1.6-.3 2.4-.3.8 0 1.7.1 2.4.3 1.9-1.3 2.7-1 2.7-1 .5 1.3.2 2.3.1 2.6.6.7 1 1.5 1 2.6 0 3.7-2.3 4.6-4.4 4.8.4.3.7.9.7 1.8V21c0 .3.2.6.7.5 3.9-1.3 6.6-4.9 6.6-9.2 0-5.4-4.4-9.8-9.8-9.8z"></path></svg></a><a href="https://github.com/UCB-stat-159-f25/proj02-group7/edit/main/proj02-nlp.ipynb" title="Edit This Page" target="_blank" rel="noopener noreferrer" class="text-inherit hover:text-inherit"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.25rem" height="1.25rem" class="inline-block mr-1 opacity-60 hover:opacity-100"><path stroke-linecap="round" stroke-linejoin="round" d="m16.862 4.487 1.687-1.688a1.875 1.875 0 1 1 2.652 2.652L10.582 16.07a4.5 4.5 0 0 1-1.897 1.13L6 18l.8-2.685a4.5 4.5 0 0 1 1.13-1.897l8.932-8.931Zm0 0L19.5 7.125M18 14v4.75A2.25 2.25 0 0 1 15.75 21H5.25A2.25 2.25 0 0 1 3 18.75V8.25A2.25 2.25 0 0 1 5.25 6H10"></path></svg></a><div class="relative flex inline-block mx-1 grow-0" data-headlessui-state=""><button class="relative ml-2 -mr-1" id="headlessui-menu-button-:Rs8top:" type="button" aria-haspopup="menu" aria-expanded="false" data-headlessui-state=""><span class="sr-only">Downloads</span><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.25rem" height="1.25rem"><title>Download</title><path stroke-linecap="round" stroke-linejoin="round" d="M3 16.5v2.25A2.25 2.25 0 0 0 5.25 21h13.5A2.25 2.25 0 0 0 21 18.75V16.5M16.5 12 12 16.5m0 0L7.5 12m4.5 4.5V3"></path></svg></button></div></div><h1 class="mb-0">Project 2: Reproducibility in Natural Language Processing</h1><header class="mt-4 not-prose"><div class="grid grid-cols-1 sm:grid-cols-2 gap-y-1"><div class="pb-2 text-xs font-thin uppercase">Authors</div><div class="pb-2 text-xs font-thin uppercase">Affiliations</div><div><span class="font-semibold text-sm"><button class="focus:shadow-[0_0_0_2px] focus:shadow-black outline-none hover:underline" aria-label="Author Details" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-:Rad8top:" data-state="closed">Reily Fairchild</button></span></div><div class="text-sm"><div>UC Berkeley<!-- --> </div></div><div><span class="font-semibold text-sm"><button class="focus:shadow-[0_0_0_2px] focus:shadow-black outline-none hover:underline" aria-label="Author Details" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-:Ral8top:" data-state="closed">Atiila Joselyn Birah Kharobo</button></span></div><div class="text-sm"><div>UC Berkeley<!-- --> </div></div><div><span class="font-semibold text-sm"><button class="focus:shadow-[0_0_0_2px] focus:shadow-black outline-none hover:underline" aria-label="Author Details" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-:Rat8top:" data-state="closed">Jordan Elizabeth Collins</button></span></div><div class="text-sm"><div>UC Berkeley<!-- --> </div></div><div><span class="font-semibold text-sm"><button class="focus:shadow-[0_0_0_2px] focus:shadow-black outline-none hover:underline" aria-label="Author Details" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-:Rb58top:" data-state="closed">Aditya Jagannadha Sai Mangalampalli</button></span></div><div class="text-sm"><div>UC Berkeley<!-- --> </div></div></div></header></div><div class="block my-10 lg:sticky lg:z-10 lg:h-0 lg:pt-0 lg:my-0 lg:ml-10 lg:col-margin-right" style="top:60px"><nav></nav></div><div id="skip-to-article"></div><div id="Ndef6nPnyj" class="relative group/block"><h2 id="part-1-data-loading-and-initial-exploration-15-pts" class="relative group"><span class="heading-text">Part 1: Data Loading and Initial Exploration (15 pts)</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#part-1-data-loading-and-initial-exploration-15-pts" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><p>The data for this project is stored in the <code>data</code> folder in your repositories, in the <code>SOTU.csv</code> file. The data file is structured as a CSV with columns for president name, speech text, year, and word count in the speech.</p><p>In this section you will:</p><ol start="1"><li><p>Import the data into a pandas dataframe</p></li><li><p>Perform exploratory data analysis (EDA) including specifically:</p></li></ol><ul><li><p>Analyze the number of speeches per president</p></li><li><p>Analyze the number of speeches per year</p></li><li><p>Analyze the word count distribution</p></li><li><p>Analyze the word count distribution accross years using a rug plot</p></li><li><p>Analyze the average word count per president</p></li></ul><ol start="3"><li><p>Write commentary on your findings</p></li></ol><p>First, create the <code>conda</code> environment with the provided yaml file. Note, it’s not unusual for it to take ~15 minutes for the environment to fully install.</p></div><div id="kOqSfemAwu" class="relative group/block"><h3 id="read-data" class="relative group"><span class="heading-text">Read Data</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#read-data" title="Link to this Section" aria-label="Link to this Section">¶</a></h3></div><div id="uUDMAZ9fCM" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># imports
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

plt.style.use(&#x27;seaborn-v0_8-dark&#x27;) </code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="YjOU0jlSz6KB5VllL6l6Z" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left"></div></div><div id="JtnYYBrvIp" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># read in SOTU.csv using pandas, name the variable `sou` for simplicity
# the below cell is what the output should look like
sou = pd.read_csv(&#x27;data/SOTU.csv&#x27;)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="F9QjN43Pzht_Nk_bp-AzS" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left"></div></div><div id="MX5wPr9nQK" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">sou</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="EewBW1SkcpG5Sz-hBk1XP" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left"></div></div><div id="D1SCQuh88K" class="relative group/block"><h3 id="exploratory-data-analysis" class="relative group"><span class="heading-text">Exploratory Data Analysis</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#exploratory-data-analysis" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><p>Replicate the plots below using the hints specified. For each plot, provide some commentary describing the results/anything interesting you might see.</p></div><div id="fJLpgpgZqk" class="relative group/block"><h4 id="number-of-speeches-per-president" class="relative group"><span class="heading-text">Number of Speeches per President</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#number-of-speeches-per-president" title="Link to this Section" aria-label="Link to this Section">¶</a></h4></div><div id="RhRGwjqJSq" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># Hint - use value_counts() on the President column
# Hint - sort in order of dataframe
counts = sou[&quot;President&quot;].value_counts(sort=False)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="NsCtUHvNZyLIdL_ueivnw" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left"></div></div><div id="Pl1cQFMjZV" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># Plot 
# Hint - use the .plot() method for Pandas Series, make sure all presidents show up on x-axis

counts.plot(kind=&quot;bar&quot;, figsize=(20, 10))
plt.title(&quot;Number of Speeches per President&quot;, fontsize=24)
plt.xlabel(&quot;President&quot;, fontsize=18)
plt.ylabel(&quot;Count&quot;, fontsize=18)
plt.xticks(rotation=90, fontsize=13)
plt.yticks(fontsize=13)

plt.show()</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="YKlCok5ILj5orPsDNPu7D" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left"></div></div><div id="b3FIjbGJ0g" class="relative group/block"><h4 id="number-of-speeches-per-year" class="relative group"><span class="heading-text">Number of Speeches per Year</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#number-of-speeches-per-year" title="Link to this Section" aria-label="Link to this Section">¶</a></h4></div><div id="JvFb2IoFIf" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># Hint - Use value counts and sort by years
counts_by_year = sou[&quot;Year&quot;].value_counts().sort_index()

plt.figure(figsize=(5.75, 5))
counts_by_year.plot(kind=&quot;line&quot;)

plt.title(&quot;Number of State of the Union Speeches per Year&quot;)
plt.xlabel(&quot;Year&quot;)
plt.ylabel(&quot;Count&quot;)

plt.tight_layout()
plt.show()</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="YiNbpKw_F5kg7OCnFiTgo" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left"></div></div><div id="PSYhTDw8JE" class="relative group/block"><h4 id="word-count-distribution" class="relative group"><span class="heading-text">Word Count Distribution</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#word-count-distribution" title="Link to this Section" aria-label="Link to this Section">¶</a></h4></div><div id="OtLIiiNAU2" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># Hint - try seaborn.histplot()

plt.figure(figsize=(5.75, 5))

sns.histplot(
    sou[&quot;Word Count&quot;],
    bins=18,
    kde=False,
    color=&quot;steelblue&quot;
)

plt.title(&quot;Distribution of State of the Union Speech\nWord Counts&quot;)
plt.xlabel(&quot;Word Count&quot;)
plt.ylabel(&quot;Count&quot;)

plt.tight_layout()
plt.show()</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="y74_8_0L6BYf9KVuPI0M3" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left"></div></div><div id="rlz5OTB7h5" class="relative group/block"><h4 id="word-count-distribution-over-year" class="relative group"><span class="heading-text">Word Count Distribution over Year</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#word-count-distribution-over-year" title="Link to this Section" aria-label="Link to this Section">¶</a></h4></div><div id="JMZ1u2qzKm" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># Hint: try seaborn.rugplot()
plt.figure(figsize=(6, 5))

sns.scatterplot(
    data=sou,
    x=&quot;Word Count&quot;,
    y=&quot;Year&quot;,
    s=40
)

sns.rugplot(
    data=sou,
    x=&quot;Word Count&quot;,
    height=0.02,
    alpha=0.6,
)

sns.rugplot(
    data=sou,
    y=&quot;Year&quot;,
    height=0.02,
    alpha=1,
    color=(59/255, 117/255, 174/255)
)

plt.title(&quot;Speech Year Versus Word Count&quot;)
plt.xlabel(&quot;Word Count&quot;)
plt.ylabel(&quot;Year&quot;)

plt.tight_layout()
plt.show()</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="SVW8N4clc9JRYXrOcRvu1" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left"></div></div><div id="IFFIJvQbG7" class="relative group/block"><h4 id="word-count-distribution-per-president" class="relative group"><span class="heading-text">Word Count Distribution per President</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#word-count-distribution-per-president" title="Link to this Section" aria-label="Link to this Section">¶</a></h4></div><div id="DGFKFEgDQr" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># Hint: use pandas groupby to get mean word count per president then sort by order

avg_words = sou.groupby(&quot;President&quot;)[&quot;Word Count&quot;].mean()

avg_words = avg_words.loc[sou[&quot;President&quot;].unique()]
plt.figure(figsize=(10, 6))
avg_words.plot(kind=&quot;bar&quot;)

plt.title(&quot;Average State of the Union Word Count\nper President&quot;)
plt.xlabel(&quot;President&quot;)
plt.ylabel(&quot;Average Word Count&quot;)

plt.xticks(rotation=90)
plt.tight_layout()
plt.show()</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="ZLeaLPNgHoQviP6d9RAbg" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left"></div></div><div id="zKurezoQAm" class="relative group/block"><h2 id="part-2-simple-text-processing-tokenization-lemmatization-word-frequency-vectorization-20-pts" class="relative group"><span class="heading-text">Part 2: Simple Text Processing - Tokenization, Lemmatization, Word Frequency, Vectorization (20 pts)</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#part-2-simple-text-processing-tokenization-lemmatization-word-frequency-vectorization-20-pts" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><p>Now we will start working on simple text processing using the <code>SpaCy</code> package and the same dataset as Part 1. The package should already be included in the <code>environment.yml</code>. However, we will also need to download <code>en_core_web_sm</code>, an English language text processing model. To do this, while having your <code>sotu</code> environment activated, run the following:</p><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 bg-stone-200/10"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-text" style="white-space:pre">python -m spacy download en_core_web_sm</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><p>Now, you should be good to go!</p><p>Some important definitions:</p><ul><li><p><em>Token</em>: a single word or piece of a word</p></li><li><p><em>Lemma</em>: the core component of a word, e.g., “complete” is the lemma for “completed” and “completely”</p></li><li><p><em>Stop Word</em>: a common word that does not add semantic value, such as “a”, “and”, “the”, etc.</p></li><li><p><em>Vectorization</em>: representing a document as a vector where each index in the vector corresponds to a token or word and each entry is the count.</p></li></ul><p>In this section, we will explore the most common tokens and lemmas throughout different slices of the speech data. We will also develop vectorization representations of the speeches.</p><p>The core steps are:</p><ol start="1"><li><p>Process speeches using the SpaCy nlp module</p></li><li><p>Analyze Tokens vs Lemmas:</p></li></ol><ul><li><p>Create a list of all tokens across all speeches that are not stop words, punctuation, or spaces.</p></li><li><p>Create a second list of the lemmas for these same tokens.</p></li><li><p>Display the top 25 for each of these and compare.</p></li></ul><ol start="3"><li><p>Analyze common word distributions over different years:</p></li></ol><ul><li><p>Create a function that takes the dataset and a year as an input and outputs the top n lemmas for that year’s speeches</p></li><li><p>Compare the top 10 words for 2023 versus 2019</p></li></ul><ol start="4"><li><p>Document Vectorization:</p></li></ol><ul><li><p>Train a Term Frequency-Inverse Document Frequency (TF-IDF) vectorization model using your processed dataset and scikit learn</p></li><li><p>Output the feature vectors</p></li></ul><p><strong>Helpful Resources:</strong></p><ul><li><p><a target="_blank" rel="noreferrer" href="https://realpython.com/natural-language-processing-spacy-python/" class="">https://<wbr/>realpython<wbr/>.com<wbr/>/natural<wbr/>-language<wbr/>-processing<wbr/>-spacy<wbr/>-python/</a></p></li><li><p><a target="_blank" rel="noreferrer" href="https://www.statology.org/text-preprocessing-feature-engineering-spacy/" class="">https://<wbr/>www<wbr/>.statology<wbr/>.org<wbr/>/text<wbr/>-preprocessing<wbr/>-feature<wbr/>-engineering<wbr/>-spacy/</a></p></li><li><p><a target="_blank" rel="noreferrer" href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html#" class="">https://<wbr/>scikit<wbr/>-learn<wbr/>.org<wbr/>/stable<wbr/>/modules<wbr/>/generated<wbr/>/sklearn<wbr/>.feature<wbr/>_extraction<wbr/>.text<wbr/>.TfidfVectorizer<wbr/>.html#</a></p></li><li><p><a target="_blank" rel="noreferrer" href="https://www.geeksforgeeks.org/nlp/how-to-store-a-tfidfvectorizer-for-future-use-in-scikit-learn/" class="">https://<wbr/>www<wbr/>.geeksforgeeks<wbr/>.org<wbr/>/nlp<wbr/>/how<wbr/>-to<wbr/>-store<wbr/>-a<wbr/>-tfidfvectorizer<wbr/>-for<wbr/>-future<wbr/>-use<wbr/>-in<wbr/>-scikit<wbr/>-learn/</a></p></li></ul></div><div id="lSIe7UR8pG" class="relative group/block"><h3 id="processing-speeches-with-spacy" class="relative group"><span class="heading-text">Processing Speeches with SpaCy</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#processing-speeches-with-spacy" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><p>Lets study just speeches from 2000 and onwards to begin with. So, be sure to subset your DataFrame to just these speeches before continuing!</p></div><div id="uPS4nk89l1" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">import spacy
from tqdm import tqdm
from collections import Counter

nlp = spacy.load(&quot;en_core_web_sm&quot;)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="rowR77LM9xC30OfPHINuU" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left"></div></div><div id="kzhzhnm7Vn" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">sou_new = sou[sou[&#x27;Year&#x27;] &gt;= 2000]
sou_new</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="s6iTfy66Rgs0mV6C4LUVF" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left"></div></div><div id="MTVhpRdgm4" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">processed_speeches = []

for i in range(len(sou_new)):
    speech_text = sou_new.loc[i, &#x27;Text&#x27;] 
    processed = nlp(speech_text)    
    processed_speeches.append(processed)
</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="b5L0KmMZHI1wpmLmECN5N" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left"></div></div><div id="ha9s8C7xg9" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"></code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="R69WQ2DUaf-I0KCazzypf" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left"></div></div><div id="c8zCFpaKqB" class="relative group/block"><h3 id="analyze-tokens-vs-lemmas" class="relative group"><span class="heading-text">Analyze Tokens vs Lemmas</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#analyze-tokens-vs-lemmas" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><h4 id="token-list" class="relative group"><span class="heading-text">Token List</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#token-list" title="Link to this Section" aria-label="Link to this Section">¶</a></h4><p>Create a list of tokens across all speeches that are not spaces, stopwords, or punctuation. Make each token lowercase as well. <em>Hint: each element of the list we just created are themselves lists of tokens. Token objects have attributes <code>is_stop</code>, <code>is_punct</code>, and <code>is_space</code>.</em></p></div><div id="N28xoEDDKq" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">tokens = []

for speech in processed_speeches:
    for token in speech:
        if not token.is_punct and not token.is_space and not token.is_stop:
            tokens.append(token.text.lower())

</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="3Rkj9bAIOdQEDa8z-lP6F" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left"></div></div><div id="VmRq7EDiUQ" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># print top 20 tokens
token_counts = Counter(tokens).most_common(20)
token_counts
</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="xeM8Ub_nFsDC1lryVArWR" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left"></div></div><div id="sdmgoo4dKC" class="relative group/block"><h4 id="lemma-list" class="relative group"><span class="heading-text">Lemma List</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#lemma-list" title="Link to this Section" aria-label="Link to this Section">¶</a></h4><p>Do the same as above, but for lemmas. <em>Hint: recall lemmas are components of words. Each token should have an attribute to extract the lemma.</em></p></div><div id="oNwy3SPnWX" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">lemmas = []

for word in tokens:
    doc = nlp(word)  
    for token in doc:
        lemmas.append(token.lemma_.lower())
</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="O1Ly3b9HsyaJKQooFwSet" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left"></div></div><div id="BW0svAfM3m" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># print top 20 lemmas
lemma_counts = Counter(lemmas).most_common(20)
lemma_counts</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="pHfFzU8dQqqbyJ_vBjBwH" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left"></div></div><div id="VlG8jit8lL" class="relative group/block"><h4 id="token-versus-lemma-comparison" class="relative group"><span class="heading-text">Token versus Lemma Comparison</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#token-versus-lemma-comparison" title="Link to this Section" aria-label="Link to this Section">¶</a></h4><p>What do you notice about the top tokens versus the top lemmas?
Consider two tokens - “year” and “years” - how do their counts compare to the lemma “year”?
What about the lemma “child”?</p></div><div id="naGyUn39tD" class="relative group/block"><p>Tokens ‘years’ and ‘year’ are common tokens, appearing in the 5th and 7th most common slots, respectively. The lemma ‘year’
is the most popular lemma and its occurance is the sum of the occurences of its similar tokens. Although ‘child’ does not appear in the top 20 tokens, it does appear as the 17th most common lemma. This could be becuase there are many tokens related to the lemma ‘child’ such as ‘child,’ ‘children,’ ‘childish,’ and ‘childrens’.’ This is twice the amount of tokens related to the same lemma of ‘child’ as there is for the lemma of ‘year.’</p></div><div id="w0MqGb1TBH" class="relative group/block"><h3 id="common-words" class="relative group"><span class="heading-text">Common Words</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#common-words" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><h4 id="common-words-per-year-function" class="relative group"><span class="heading-text">Common Words per Year Function</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#common-words-per-year-function" title="Link to this Section" aria-label="Link to this Section">¶</a></h4><p>Fill in the below function to obtain the n-most common words in speeches for a given year.</p><p>inputs:</p><ul><li><p>df raw unprocessed sou dataframe</p></li><li><p>year</p></li><li><p>n
outputs:</p></li><li><p>top n words for that years</p></li></ul><p>steps:</p><ul><li><p>subset the dataframe for the year of interest - note the years might not be in int type</p></li><li><p>process the subsetted dataframe with spacy</p></li><li><p>get the lemmas across all those speeches</p></li><li><p>count the top n lemmas</p></li></ul></div><div id="v1VEsxTTkJ" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">def get_most_common_words(df, year, n=25):
    &quot;&quot;&quot;
    Processes the SOTU speech for a given year and returns
    the most common non-stopword/punctuation lemmas.

    INPUTS
    - raw unprocessed sou data frame
    - year

    OUTPUTS
    - top n words for that year
    &quot;&quot;&quot;

    # Step 1: Subset df
    new_df = df[df[&#x27;Year&#x27;] == year]
    
    # Step 2: Process the text with spaCy
    new_df = df[df[&#x27;Year&#x27;] == year].reset_index(drop=True) 
    processed_speeches = []

    for i in range(len(new_df)):
        speech_text = new_df.loc[i, &#x27;Text&#x27;] 
        processed = nlp(speech_text)    
        processed_speeches.append(processed)
    
    # Step 3: Get lemmas
    lemmas = []

    for doc in processed_speeches:
        for token in doc:
            if not token.is_punct and not token.is_space and not token.is_stop:
                lemmas.append(token.lemma_.lower())
    
    lemma_counts = Counter(lemmas).most_common(n)
    
    return lemma_counts</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="oqwMpFeeqBbl49letxr0W" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left"></div></div><div id="DDu8GfRACO" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># test it on 2024
get_most_common_words(sou, 2024, n=20)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="h_Yhh3NFKZwsBmhjCDrg3" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left"></div></div><div id="vKkM326Z98" class="relative group/block"><h4 id="compare-2023-to-2017" class="relative group"><span class="heading-text">Compare 2023 to 2017</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#compare-2023-to-2017" title="Link to this Section" aria-label="Link to this Section">¶</a></h4><p>Run your function from the previous step to get the top 20 words for 2017 and 2023. Plot the words and their frequencies in a barchart and replicate the figure below.</p></div><div id="An95TyGvNi" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">words_2023 = get_most_common_words(sou, 2023, n=20)
words_2017 = get_most_common_words(sou, 2017, n=20)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="FdrA1HfKTDkT8CmG_Kc_j" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left"></div></div><div id="Gf01Mhf86y" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">words_2023</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="UU2keyLdoA2vG7xL84I6c" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left"></div></div><div id="Q2MFkImdEH" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">words_2017</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="JntGXAywBjr2hbj1RTXYG" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left"></div></div><div id="xFuw5qsnHl" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># Hint - put the words and counts into a pd Dataframe for better structure
# and to make plotting easier
df_2017 = pd.DataFrame(words_2017, columns=[&#x27;lemma&#x27;, &#x27;count&#x27;])
df_2023 = pd.DataFrame(words_2023, columns=[&#x27;lemma&#x27;, &#x27;count&#x27;])</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="Q27LwwfBPgu5qBqeheAxi" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left"></div></div><div id="pEQVnH1PjU" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># Hint - use seaborn, subplots, and rotate tick labels

fig, axes = plt.subplots(2, 1, figsize=(12, 10)) 
# Plot 2017
sns.barplot(
    x = &#x27;lemma&#x27;,
    y = &#x27;count&#x27;,
    data = df_2017,
    ax = axes[0],
     color=&#x27;#2C7BA1&#x27;
    
)
axes[0].set_title(&#x27;2017 State of the Union Most Frequent Words&#x27;)
axes[0].set_xlabel(&#x27;Word&#x27;)
axes[0].set_ylabel(&#x27;Count&#x27;)
axes[0].tick_params(axis=&#x27;x&#x27;, rotation=45) 

# Plot 2023
sns.barplot(
    x=&#x27;lemma&#x27;,
    y=&#x27;count&#x27;,
    data=df_2023,
    ax=axes[1],
    color=&#x27;#2C7BA1&#x27;
)

axes[1].set_title(&#x27;2023 State of the Union Most Frequent Words&#x27;)
axes[1].set_xlabel(&#x27;Word&#x27;)
axes[1].set_ylabel(&#x27;Count&#x27;)
axes[1].tick_params(axis=&#x27;x&#x27;, rotation=45)

plt.tight_layout()</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="5gbWgp0RWmwgvMUaIF8Mz" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left"></div></div><div id="mscNPp7UYx" class="relative group/block"><h3 id="tf-idf-vectorization" class="relative group"><span class="heading-text">TF-IDF Vectorization</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#tf-idf-vectorization" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><p>To use statsitical alorithms on documents, we need to transform them into vectors, where each element of the vector corresponds to a particular word in a document or corpus of documents. One common way is via TF-IDF embeddings. LLMs work similarly - they typically use transformer models to generate text embeddings before sending text through a deep neural network.</p><p>Here we will fit a TF-IDF vectorizer, plot all the speeches on a 2-D grid using PCA and also using a heatmap, and examine TF-IDF scores for the top 10 most common words in the first speech. This is a good resource here: <a target="_blank" rel="noreferrer" href="https://medium.com/GeoffreyGordonAshbrook/vector-visualization-2d-plot-your-tf-idf-with-pca-83fa9fccb1d" class="">https://<wbr/>medium<wbr/>.com<wbr/>/GeoffreyGordonAshbrook<wbr/>/vector<wbr/>-visualization<wbr/>-2d<wbr/>-plot<wbr/>-your<wbr/>-tf<wbr/>-idf<wbr/>-with<wbr/>-pca<wbr/>-83fa9fccb1d</a></p></div><div id="KgbJvJbYOX" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.decomposition import PCA</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="rHpfaPh8CJAOMTWvFIZbV" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left"></div></div><div id="Hg79cght60" class="relative group/block"><h4 id="train-the-vectorizer-and-transform-the-data" class="relative group"><span class="heading-text">Train the Vectorizer and Transform the Data</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#train-the-vectorizer-and-transform-the-data" title="Link to this Section" aria-label="Link to this Section">¶</a></h4></div><div id="G6r4M6anl8" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># you may use this as input to fit the TF-IDF vectorizer
raw_docs = sou[&quot;Text&quot;].to_list()</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="Fox36X2GWY6TsT7vNDyD_" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left"></div></div><div id="ZLkwmCwjoK" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># Hint - use fit_transform for vectorizer and PCA</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="VqJtHpoAZgGyqjWslqEjr" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left"></div></div><div id="YgUpyTes0l" class="relative group/block"><p>The output of <code>fit_transform()</code> will be a matrix where each row corresponds to a speech, each column corresponds to a word in the corpus of speeches, and the value is the TF-IDF score which measures the importance of that word in that speech, relative to the rest of the speeches.</p></div><div id="aIO90y9hxe" class="relative group/block"><h4 id="plot-speeches" class="relative group"><span class="heading-text">Plot Speeches</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#plot-speeches" title="Link to this Section" aria-label="Link to this Section">¶</a></h4><ul><li><p>First used PCA to generate the first chart</p></li><li><p>Second use seaborn heatmap with a log-scaled color axis to generate the second chart</p></li></ul></div><div id="HWDw0nVqyi" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># Step 1: Set PCA to find first 2 principal components

# Step 2: Create a new dataframe where each row is a speech, and each column is a projection onto
# one of the two principal components

# Plot Data Visualization (Matplotlib)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="ZOKirdSFGHaoUd3EM81zJ" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left"></div></div><div id="kghYVWRMZj" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># Hint - vectorized_docs is a sparse matrix whose rows are speeches and columns are tokens, with each
# value being a TF-IDF score. Densify this array first, and then plot using seaborn.</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="RcpN7yAMALL7DF7AN0Dw_" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left"></div></div><div id="v44VPqJMP0" class="relative group/block"><h4 id="get-the-tf-idf-value-for-certain-words-and-documents" class="relative group"><span class="heading-text">Get the TF-IDF value for certain words and documents</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#get-the-tf-idf-value-for-certain-words-and-documents" title="Link to this Section" aria-label="Link to this Section">¶</a></h4></div><div id="PRmpmd6lTk" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">word_list = [&#x27;year&#x27;,
 &#x27;america&#x27;,
 &#x27;people&#x27;,
 &#x27;american&#x27;,
 &#x27;work&#x27;,
 &#x27;new&#x27;,
 &#x27;job&#x27;,
 &#x27;country&#x27;,
 &#x27;americans&#x27;,
 &#x27;world&#x27;] # top ten most common words through whole corpus</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="b74jW-oUdzg2xFVCjdMi6" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left"></div></div><div id="PZoQdfzjDT" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">word_nums = ... # get each word&#x27;s index number using the .vocabular_ attributed of vectorizer</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="2hOgwGitLjt74cJy29BhL" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left"></div></div><div id="OKEnWqcFZk" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">idf_score = ... # get their IDF score by using .idf_ at the indices from the previous step</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="vKY9-CJBPwpkoY4akp4vs" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left"></div></div><div id="yHYtIsRs26" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">tf_idf = ... # get the tf_idf score for the first speech</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="UIKzPCV6RWPeQTUDZxLjm" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left"></div></div><div id="wrVzTupQIC" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">pd.DataFrame({&quot;Word&quot;: word_list, &quot;IDF Score&quot;: idf_score, &quot;TF-IDF Score&quot;: tf_idf})</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="A10ge9uxry98JB-C9HGRQ" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left"></div></div><div id="MIafS49t28" class="relative group/block"><h2 id="part-3-advanced-text-processing-lda-and-bertopic-topic-modeling-20-pts" class="relative group"><span class="heading-text">Part 3: Advanced Text Processing - LDA and BERTopic Topic Modeling (20 pts)</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#part-3-advanced-text-processing-lda-and-bertopic-topic-modeling-20-pts" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><p><strong>Resources:</strong></p><ul><li><p>LDA:</p><ul><li><p><a target="_blank" rel="noreferrer" href="https://medium.com/sayahfares19/text-analysis-topic-modelling-with-spacy-gensim-4cd92ef06e06" class="">https://<wbr/>medium<wbr/>.com<wbr/>/sayahfares19<wbr/>/text<wbr/>-analysis<wbr/>-topic<wbr/>-modelling<wbr/>-with<wbr/>-spacy<wbr/>-gensim<wbr/>-4cd92ef06e06</a></p></li><li><p><a target="_blank" rel="noreferrer" href="https://www.kaggle.com/code/faressayah/text-analysis-topic-modeling-with-spacy-gensim#%F0%9F%93%9A-Topic-Modeling" class="">https://<wbr/>www<wbr/>.kaggle<wbr/>.com<wbr/>/code<wbr/>/faressayah<wbr/>/text<wbr/>-analysis<wbr/>-topic<wbr/>-modeling<wbr/>-with<wbr/>-spacy<wbr/>-gensim<wbr/>#📚<wbr/>-Topic<wbr/>-Modeling</a> (code for previous post)</p></li><li><p><a target="_blank" rel="noreferrer" href="https://towardsdatascience.com/topic-modelling-in-python-with-spacy-and-gensim-dc8f7748bdbf/" class="">https://<wbr/>towardsdatascience<wbr/>.com<wbr/>/topic<wbr/>-modelling<wbr/>-in<wbr/>-python<wbr/>-with<wbr/>-spacy<wbr/>-and<wbr/>-gensim<wbr/>-dc8f7748bdbf/</a></p></li></ul></li><li><p>BERTopic:</p><ul><li><p><a target="_blank" rel="noreferrer" href="https://maartengr.github.io/BERTopic/getting_started/visualization/visualize_documents.html#visualize-documents-with-plotly" class="">https://<wbr/>maartengr<wbr/>.github<wbr/>.io<wbr/>/BERTopic<wbr/>/getting<wbr/>_started<wbr/>/visualization<wbr/>/visualize<wbr/>_documents<wbr/>.html<wbr/>#visualize<wbr/>-documents<wbr/>-with<wbr/>-plotly</a></p></li><li><p><a target="_blank" rel="noreferrer" href="https://maartengr.github.io/BERTopic/getting_started/visualization/visualize_topics.html" class="">https://<wbr/>maartengr<wbr/>.github<wbr/>.io<wbr/>/BERTopic<wbr/>/getting<wbr/>_started<wbr/>/visualization<wbr/>/visualize<wbr/>_topics<wbr/>.html</a></p></li></ul></li></ul></div><div id="YodmfgM9kT" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">import spacy
from tqdm import tqdm
from collections import Counter
import pandas as pd

# imports
import matplotlib.pyplot as plt
import seaborn as sns

plt.style.use(&#x27;seaborn-v0_8-dark&#x27;) 

sou = pd.read_csv(&#x27;data/SOTU.csv&#x27;)
nlp = spacy.load(&quot;en_core_web_sm&quot;)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="4i7kJTIWxtauD2Y7QSax4" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left"></div></div><div id="QcHZRdA9qN" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">from spacy import displacy
from bertopic import BERTopic
from gensim.corpora import Dictionary
from gensim.models import LdaModel
from sklearn.feature_extraction.text import CountVectorizer
import pyLDAvis
import pyLDAvis.gensim_models</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="WvkRfRN3JusJ5M48qQZDI" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left"></div></div><div id="QLpJAmqYO5" class="relative group/block"><h3 id="lda" class="relative group"><span class="heading-text">LDA</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#lda" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><ul><li><p>Train an LDA model with 18 topics</p></li><li><p>Output the top 10 words for each topic.</p></li><li><p>Output the topic distribution for the first speech</p></li><li><p>Make a visualization</p></li></ul></div><div id="mbU7EtfPIg" class="relative group/block"><p>You may use the next two cells to process the data.</p></div><div id="NAcd3pGvo7" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">def preprocess_text(text): 
    doc = nlp(text) 
    return [token.lemma_.lower() for token in doc if not token.is_stop and not token.is_punct and not token.is_space and len(token.lemma_) &gt; 3]</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="rBzEsXBs7JZfRYzVqrUNo" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left"></div></div><div id="ljwXBkvbss" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># Process all texts - note this takes ~ 5 minutes to run
processed_docs = sou[&#x27;Text&#x27;].apply(preprocess_text)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="FdajRZaOgVZYJDGM5-Qte" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left"></div></div><div id="iXsT97Kk9o" class="relative group/block"><p>To train an LDA model, use the LdaModel function that we imported a couple of cells back. The last resource linked under the LDA section is especially useful for walking through the steps we have below. <em>Note: one of the arguments to the LdaModel function is <code>random_state</code> which specifies the random seed for reproducibility. Please set yours to 42. Further, the last resource provided uses <code>LdaMulticore</code> which is essentially a parallelizable version of our function <code>LdaModel</code>. Use <code>LdaModel</code> instead, but the usage will be similar, except you can ignore the <code>iterations</code> and <code>workers</code> arguments..</em>.</p></div><div id="EeSdls9YYT" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># Build dictionary from processed_docs, which is a list of tokens extracted from our speeches

sou[&#x27;tokens&#x27;] = processed_docs
#Gensim Dictionary object maps each word to their unique ID:
dictionary = Dictionary(sou[&#x27;tokens&#x27;])
#print(dictionary.token2id)
#dictionary.filter_extremes(no_below=5, no_above=0.5, keep_n=1000)

#create sparse vector (i, j) where i is dictionary id and j is number of occurences of that distinct word (?)
corpus = [dictionary.doc2bow(doc) for doc in sou[&#x27;tokens&#x27;]]</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="YjdWy1ao7o6x48GdXUXs_" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left"></div></div><div id="WoAZuhyAKA" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># train LDA model with 18 topics
lda_model = LdaModel(corpus=corpus, id2word=dictionary, num_topics=18, random_state=42, passes=10)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="qQbuIV5ItDQwGKuGGVJui" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left"></div></div><div id="ksXCNlxWzk" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># print the top 10 words for each topic
lda_model.print_topics(-1)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="_5oqISAsrt_cYpBtjXuhB" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left"></div></div><div id="njUMumtKtS" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># print the topic distribution for the first speech
sou[&#x27;Text&#x27;][0]
lda_model[corpus][0]</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="Kcd4P20F03xnRgT_yNCaA" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left"></div></div><div id="GmOi6bh1KH" class="relative group/block"><p>The first speech is 99% belonging to topic 2!</p></div><div id="sLnNxelbmL" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># make a visualization using pyLDAvis
pyLDAvis.enable_notebook()

lda_display = pyLDAvis.gensim_models.prepare(lda_model, corpus, dictionary)
pyLDAvis.display(lda_display)
</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="EMVb3916xHFqkDimbVPjq" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left"></div></div><div id="pkG8YMnZOz" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">#save to outputs
pyLDAvis.save_html(lda_display, &#x27;outputs/lda_topics.html&#x27;)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="zJfbTd7XTx3HEHIjlyDjW" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left"></div></div><div id="JBImfk3bIX" class="relative group/block"><h3 id="bertopic" class="relative group"><span class="heading-text">BERTopic</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#bertopic" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><ul><li><p>Train a BERTopic model with a <code>min_topic_size</code> of 3 <em>Hint: use <code>BERTopic</code> to instantiate the model and specify <code>min_topic_size</code> in here. Actually fit the model using <code>fit_transform</code>, which <code>docs</code> passed into this.</em></p></li><li><p>Output the top 10 words for each topic.</p></li><li><p>Output the topic distribution for the first speech</p></li><li><p>Make a visualization of the topics (see topic_model.visualize_topics())</p></li></ul></div><div id="gdd7PiqKET" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">from bertopic import BERTopic
from sklearn.datasets import fetch_20newsgroups
from sklearn.feature_extraction.text import CountVectorizer</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="DowdRXVRyRMPw2cg9rATF" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left"></div></div><div id="buCwiuqhTI" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">docs = sou[&#x27;Text&#x27;].to_list()</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="KE68ALN-VHCnbEXQ8zm7L" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left"></div></div><div id="vuAQFo2W7V" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># train the model - this takes about 30 seconds
topic_model = BERTopic(min_topic_size=3)
topics, probs = topic_model.fit_transform(docs)


# remove stop words from the topics (Hint: use CountVectorizer and then .update_topics on topic_model)
vectorizer_model = CountVectorizer(stop_words=&quot;english&quot;)
topic_model.update_topics(docs, vectorizer_model=vectorizer_model) </code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="_znWn5buGXPTtCsi6SvRB" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left"></div></div><div id="YTP3hvnzEt" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># output the top 10 words for each topic - hint see get_topic_info
topic_model.get_topic_info()[&#x27;Representation&#x27;]</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="UVb9UiBLCqwBCgoXX9FdH" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left"></div></div><div id="XtQf0PhX4j" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># output the topic distribution for the first speech
topic_distr, _ = topic_model.approximate_distribution(docs)
first_speech_viz = topic_model.visualize_distribution(topic_distr[1])

#save first speech topic distribution to outputs
first_speech_viz.write_html(&quot;outputs/BERTopic_first_speech_viz.html&quot;)
first_speech_viz</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="2DibCoVs3q848AO6dVRuj" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left"></div></div><div id="FnTeKeanr4" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># run this cell to visualize the topics
viz_topics = topic_model.visualize_topics()

#save topic visualizations to output
viz_topics.write_html(&quot;outputs/BERTopic_topics_viz.html&quot;)
viz_topics</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="GR3Q7KRl7KK_c3T2h8hei" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left"></div></div><div id="sGqCJOdZSs" class="relative group/block"><h2 id="discussion-and-reflections" class="relative group"><span class="heading-text">Discussion and Reflections</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#discussion-and-reflections" title="Link to this Section" aria-label="Link to this Section">¶</a></h2></div><div id="CxLf472iyI" class="relative group/block"><p>The topic distribution across the two dimensional PCA is notably different for the LDA (bag of words) and BERTopic (semantic similarity) approaches. The LDA distribution appears to have larger clusters on the right quadrant of the analyses, with significantly smaller clusters on the left quadrant. On the other hand, the BERTopic distributions land in each quadrant of the PCA grid, with more even distribution between each in terms of cluster size. This demonstrates how the two approaches use different attributes of the speeches and different algorithms to conclude topic summaries and distributions.</p></div><div id="l1sDZ5Jp8y" class="relative group/block"><h2 id="part-4-choose-your-own-advecnture-7-points-optional-for-extra-credit" class="relative group"><span class="heading-text">Part 4: Choose your own advecnture! (7 Points; Optional for Extra Credit)</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#part-4-choose-your-own-advecnture-7-points-optional-for-extra-credit" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><p>This section is open ended and your chance to explare any advanced analysis. Please perform any additional analysis you find interesting! Suggested analyses (only do one max):</p><ul><li><p>Topic evolution over time - see <a target="_blank" rel="noreferrer" href="https://maartengr.github.io/BERTopic/getting_started/topicsovertime/topicsovertime.html#visualization" class="">https://<wbr/>maartengr<wbr/>.github<wbr/>.io<wbr/>/BERTopic<wbr/>/getting<wbr/>_started<wbr/>/topicsovertime<wbr/>/topicsovertime<wbr/>.html<wbr/>#visualization</a></p></li><li><p>Word frequency over time - does the frequency of certain words change over time</p></li><li><p>Semantic similarity - investigate similarity within and between presidents or time periods. For example, similarity between one presidents speeches, e.g. are all of Biden’s speeches similar to each other? How similar are they to Trump’s speeches? Are speeches from the 2000s more similar to each other than speeches in the 1800s? Which two presidents have the most similar speeches? See <a target="_blank" rel="noreferrer" href="https://spacy.io/usage/linguistic-features#vectors-similarity" class="">https://<wbr/>spacy<wbr/>.io<wbr/>/usage<wbr/>/linguistic<wbr/>-features<wbr/>#vectors<wbr/>-similarity</a></p></li><li><p>Named Entity Recognition - which entity types are most common in speeches? What are the most common words for each entity type - see <a target="_blank" rel="noreferrer" href="https://spacy.io/usage/linguistic-features#named-entities" class="">https://<wbr/>spacy<wbr/>.io<wbr/>/usage<wbr/>/linguistic<wbr/>-features<wbr/>#named<wbr/>-entities</a></p></li><li><p>Classification - can you build a classifier to detect democratic versus republican state of the union speeches from 1980-2024 - see <a target="_blank" rel="noreferrer" href="https://scikit-learn.org/stable/auto_examples/text/plot_document_classification_20newsgroups.html#sphx-glr-auto-examples-text-plot-document-classification-20newsgroups-py" class="">https://<wbr/>scikit<wbr/>-learn<wbr/>.org<wbr/>/stable<wbr/>/auto<wbr/>_examples<wbr/>/text<wbr/>/plot<wbr/>_document<wbr/>_classification<wbr/>_20newsgroups<wbr/>.html<wbr/>#sphx<wbr/>-glr<wbr/>-auto<wbr/>-examples<wbr/>-text<wbr/>-plot<wbr/>-document<wbr/>-classification<wbr/>-20newsgroups<wbr/>-py</a></p></li></ul></div><div id="gQnemwZUVk" class="relative group/block"><h3 id="word-frequency-over-time-does-the-frequency-of-certain-words-change-over-time" class="relative group"><span class="heading-text">Word frequency over time - does the frequency of certain words change over time</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#word-frequency-over-time-does-the-frequency-of-certain-words-change-over-time" title="Link to this Section" aria-label="Link to this Section">¶</a></h3></div><div id="q852UZkEEr" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">import re

# Define words we think are important in this case
words = [&quot;freedom&quot;, &quot;economy&quot;, &quot;security&quot;, &quot;health&quot;]


def count_word(text, word):
    &quot;&quot;&quot;
    RegEx Method to find variations of the word (case insensitive)
    &quot;&quot;&quot;
    pattern = r&#x27;\b&#x27; + re.escape(word) + r&#x27;\b&#x27;
    return len(re.findall(pattern, text, flags=re.IGNORECASE))


# Iterate through every word and get the raw count per year and then scale it
for w in words:
    raw_col = f&quot;freq_{w}&quot;
    rel_col = f&quot;rel_freq_{w}&quot;
    sou[raw_col] = sou[&quot;Text&quot;].apply(lambda x: count_word(x, w))
    sou[rel_col] = sou[raw_col] / sou[&quot;Word Count&quot;] * 1000


# Sort the values every year
sou_sorted = sou.sort_values(&quot;Year&quot;).reset_index(drop=True)

# Iterate through the words and fit a rolling average
for w in words:
    col = f&quot;rel_freq_{w}&quot;
    sou_sorted[col + &quot;_smooth&quot;] = (
        sou_sorted[col].rolling(window=10, min_periods=3).mean()
    )

plt.figure(figsize=(12, 6))

# Plot for the respective years
for w in words:
    plt.plot(
        sou_sorted[&quot;Year&quot;],
        sou_sorted[f&quot;rel_freq_{w}_smooth&quot;],
        label=w
    )

plt.title(&quot;Word Frequency Over Time (10-year rolling average)&quot;)
plt.xlabel(&quot;Year&quot;)
plt.ylabel(&quot;Relative Frequency (per 1000 words)&quot;)
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="Wl-n42C6sAGyzMYOR1Qvi" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left"></div></div><div id="m0b6j1gAtO" class="relative group/block"><h4 id="freedom" class="relative group"><span class="heading-text">Freedom</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#freedom" title="Link to this Section" aria-label="Link to this Section">¶</a></h4><p>Mentions of freedom stay low throughout the 1800s, then gradually increase in the early 20th century. The term spikes sharply during the Cold War (1970s–1990s), when U.S. presidents frequently framed politics in ideological terms. Another noticeable peak appears in the early 2000s during the post-9/11 era, when “freedom” became central to national messaging. Through time, “freedom” becomes a major rhetorical theme primarily in the modern era.</p><h4 id="economy" class="relative group"><span class="heading-text">Economy</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#economy" title="Link to this Section" aria-label="Link to this Section">¶</a></h4><p>The word economy remains rarely used before 1900, but rises significantly during major economic crises. There are clear peaks during the Great Depression (1930s), post-WWII recovery, the stagflation era (1970s), and again around the Great Recession (2008–2010). The pattern reflects how presidents address economic instability directly in their State of the Union speeches.</p><h4 id="security" class="relative group"><span class="heading-text">Security</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#security" title="Link to this Section" aria-label="Link to this Section">¶</a></h4><p>Security shows the strongest spikes of any word. Usage jumps dramatically during World War II, peaks again throughout the Cold War, and rises once more after 2001 in response to terrorism and national security concerns. This term closely tracks periods when the nation faces real or perceived threats, making it the most crisis-driven word in the group.</p><h4 id="health" class="relative group"><span class="heading-text">Health</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#health" title="Link to this Section" aria-label="Link to this Section">¶</a></h4><p>Mentions of health are almost nonexistent before the 20th century. Use rises steadily as the federal government becomes more involved in public health policy—especially around the creation of Medicare and Medicaid (1960s), health reform debates in the 1990s, the Affordable Care Act period (2009–2015), and again around 2020 during the COVID-19 pandemic. “Health” is the newest major theme in modern SOTU speeches.</p><h4 id="overall-summary" class="relative group"><span class="heading-text">Overall Summary</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#overall-summary" title="Link to this Section" aria-label="Link to this Section">¶</a></h4><p>Across all four words, usage stays low before 1900 and rises sharply in the modern era as speeches become more policy-focused. The trends reveal how presidential priorities evolve: “security” peaks during wars and threats, “economy” during financial crises, “freedom” during ideological conflicts, and “health” during healthcare policy shifts and pandemics. Together, these patterns highlight how State of the Union language reflects broad historical changes in national concerns.</p></div><div></div><div class="flex pt-10 mb-10 space-x-4"><a class="flex-1 block p-4 font-normal text-gray-600 no-underline border border-gray-200 rounded shadow-sm group hover:border-blue-600 dark:hover:border-blue-400 hover:text-blue-600 dark:hover:text-blue-400 dark:text-gray-100 dark:border-gray-500 hover:shadow-lg dark:shadow-neutral-700" href="/user/jcollins36855/myst-build/proj02-group7/nlp-p04"><div class="flex h-full align-middle"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.5rem" height="1.5rem" class="self-center transition-transform group-hover:-translate-x-1 shrink-0"><path stroke-linecap="round" stroke-linejoin="round" d="M10.5 19.5 3 12m0 0 7.5-7.5M3 12h18"></path></svg><div class="flex-grow text-right"><div class="text-xs text-gray-500 dark:text-gray-400">Stat159 Project 2 - Reproducibility in Natural Language Processing</div>Part 4</div></div></a><a class="flex-1 block p-4 font-normal text-gray-600 no-underline border border-gray-200 rounded shadow-sm group hover:border-blue-600 dark:hover:border-blue-400 hover:text-blue-600 dark:hover:text-blue-400 dark:text-gray-100 dark:border-gray-500 hover:shadow-lg dark:shadow-neutral-700" href="/user/jcollins36855/myst-build/proj02-group7/project-description"><div class="flex h-full align-middle"><div class="flex-grow"><div class="text-xs text-gray-500 dark:text-gray-400">Stat159 Project 2 - Reproducibility in Natural Language Processing</div>Project 2: Reproducibility in Natural Langauge Processing</div><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.5rem" height="1.5rem" class="self-center transition-transform group-hover:translate-x-1 shrink-0"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 4.5 21 12m0 0-7.5 7.5M21 12H3"></path></svg></div></a></div></article></main><script>((a,d)=>{if(!window.history.state||!window.history.state.key){let h=Math.random().toString(32).slice(2);window.history.replaceState({key:h},"")}try{let f=JSON.parse(sessionStorage.getItem(a)||"{}")[d||window.history.state.key];typeof f=="number"&&window.scrollTo(0,f)}catch(h){console.error(h),sessionStorage.removeItem(a)}})("positions", null)</script><link rel="modulepreload" href="/user/jcollins36855/myst-build/proj02-group7/build/entry.client-UNPC4GT3.js"/><link rel="modulepreload" href="/user/jcollins36855/myst-build/proj02-group7/build/_shared/chunk-OCTKKCIL.js"/><link rel="modulepreload" href="/user/jcollins36855/myst-build/proj02-group7/build/_shared/chunk-UAI5KRM7.js"/><link rel="modulepreload" href="/user/jcollins36855/myst-build/proj02-group7/build/_shared/chunk-2NH4LW52.js"/><link rel="modulepreload" href="/user/jcollins36855/myst-build/proj02-group7/build/_shared/chunk-F7G67JTZ.js"/><link rel="modulepreload" href="/user/jcollins36855/myst-build/proj02-group7/build/_shared/chunk-HBJK6BW3.js"/><link rel="modulepreload" href="/user/jcollins36855/myst-build/proj02-group7/build/_shared/chunk-HYMQ7M2K.js"/><link rel="modulepreload" href="/user/jcollins36855/myst-build/proj02-group7/build/_shared/chunk-OHOXABTA.js"/><link rel="modulepreload" href="/user/jcollins36855/myst-build/proj02-group7/build/_shared/chunk-OCWQY3HK.js"/><link rel="modulepreload" href="/user/jcollins36855/myst-build/proj02-group7/build/_shared/chunk-CPTH56EW.js"/><link rel="modulepreload" href="/user/jcollins36855/myst-build/proj02-group7/build/_shared/chunk-3CVK3PYF.js"/><link rel="modulepreload" href="/user/jcollins36855/myst-build/proj02-group7/build/_shared/chunk-J6FHCSRC.js"/><link rel="modulepreload" href="/user/jcollins36855/myst-build/proj02-group7/build/_shared/chunk-S4SWV34C.js"/><link rel="modulepreload" href="/user/jcollins36855/myst-build/proj02-group7/build/_shared/chunk-GUCIBHGO.js"/><link rel="modulepreload" href="/user/jcollins36855/myst-build/proj02-group7/build/root-7TUVC4ZT.js"/><link rel="modulepreload" href="/user/jcollins36855/myst-build/proj02-group7/build/_shared/chunk-INOWNUZ6.js"/><link rel="modulepreload" href="/user/jcollins36855/myst-build/proj02-group7/build/routes/$-P6PGXPYX.js"/><script>window.__remixContext = {"url":"/proj02-nlp","state":{"loaderData":{"root":{"config":{"version":2,"myst":"1.6.3","options":{},"nav":[],"actions":[],"projects":[{"title":"Stat159 Project 2 - Reproducibility in Natural Language Processing","authors":[{"nameParsed":{"literal":"Reily Fairchild","given":"Reily","family":"Fairchild"},"name":"Reily Fairchild","affiliations":["UC Berkeley"],"id":"contributors-myst-generated-uid-0"},{"nameParsed":{"literal":"Atiila Joselyn Birah Kharobo","given":"Atiila Joselyn Birah","family":"Kharobo"},"name":"Atiila Joselyn Birah Kharobo","affiliations":["UC Berkeley"],"id":"contributors-myst-generated-uid-1"},{"nameParsed":{"literal":"Jordan Elizabeth Collins","given":"Jordan Elizabeth","family":"Collins"},"name":"Jordan Elizabeth Collins","affiliations":["UC Berkeley"],"id":"contributors-myst-generated-uid-2"},{"nameParsed":{"literal":"Aditya Jagannadha Sai Mangalampalli","given":"Aditya Jagannadha Sai","family":"Mangalampalli"},"name":"Aditya Jagannadha Sai Mangalampalli","affiliations":["UC Berkeley"],"id":"contributors-myst-generated-uid-3"}],"github":"https://github.com/UCB-stat-159-f25/proj02-group7","affiliations":[{"id":"UC Berkeley","name":"UC Berkeley"}],"id":"a74ecdef-c9eb-4683-b555-417faf7e975c","toc":[{"file":"index.md"},{"file":"contributions.md"},{"file":"nlp-P01.ipynb"},{"file":"nlp-P02.ipynb"},{"file":"nlp-P03.ipynb"},{"file":"nlp-P04.ipynb"},{"file":"proj02-nlp.ipynb"},{"file":"project-description.md"}],"thumbnail":"/user/jcollins36855/myst-build/proj02-group7/build/b77199e99a54e59b2e3c037c2cc90f21.svg","exports":[],"bibliography":[],"index":"index","pages":[{"slug":"contributions","title":"Contributions","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"nlp-p01","title":"Project 2: Reproducibility in Natural Language Processing","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"nlp-p02","title":"Part 2: Simple Text Processing - Tokenization, Lemmatization, Word Frequency, Vectorization (20 pts)","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"nlp-p03","title":"Part 3: Advanced Text Processing - LDA and BERTopic Topic Modeling (20 pts)","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"nlp-p04","title":"Part 4","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"proj02-nlp","title":"Project 2: Reproducibility in Natural Language Processing","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"project-description","title":"Project 2: Reproducibility in Natural Langauge Processing","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1}]}]},"CONTENT_CDN_PORT":"3100","MODE":"static","BASE_URL":"/user/jcollins36855/myst-build/proj02-group7"},"routes/$":{"config":{"version":2,"myst":"1.6.3","options":{},"nav":[],"actions":[],"projects":[{"title":"Stat159 Project 2 - Reproducibility in Natural Language Processing","authors":[{"nameParsed":{"literal":"Reily Fairchild","given":"Reily","family":"Fairchild"},"name":"Reily Fairchild","affiliations":["UC Berkeley"],"id":"contributors-myst-generated-uid-0"},{"nameParsed":{"literal":"Atiila Joselyn Birah Kharobo","given":"Atiila Joselyn Birah","family":"Kharobo"},"name":"Atiila Joselyn Birah Kharobo","affiliations":["UC Berkeley"],"id":"contributors-myst-generated-uid-1"},{"nameParsed":{"literal":"Jordan Elizabeth Collins","given":"Jordan Elizabeth","family":"Collins"},"name":"Jordan Elizabeth Collins","affiliations":["UC Berkeley"],"id":"contributors-myst-generated-uid-2"},{"nameParsed":{"literal":"Aditya Jagannadha Sai Mangalampalli","given":"Aditya Jagannadha Sai","family":"Mangalampalli"},"name":"Aditya Jagannadha Sai Mangalampalli","affiliations":["UC Berkeley"],"id":"contributors-myst-generated-uid-3"}],"github":"https://github.com/UCB-stat-159-f25/proj02-group7","affiliations":[{"id":"UC Berkeley","name":"UC Berkeley"}],"id":"a74ecdef-c9eb-4683-b555-417faf7e975c","toc":[{"file":"index.md"},{"file":"contributions.md"},{"file":"nlp-P01.ipynb"},{"file":"nlp-P02.ipynb"},{"file":"nlp-P03.ipynb"},{"file":"nlp-P04.ipynb"},{"file":"proj02-nlp.ipynb"},{"file":"project-description.md"}],"thumbnail":"/user/jcollins36855/myst-build/proj02-group7/build/b77199e99a54e59b2e3c037c2cc90f21.svg","exports":[],"bibliography":[],"index":"index","pages":[{"slug":"contributions","title":"Contributions","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"nlp-p01","title":"Project 2: Reproducibility in Natural Language Processing","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"nlp-p02","title":"Part 2: Simple Text Processing - Tokenization, Lemmatization, Word Frequency, Vectorization (20 pts)","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"nlp-p03","title":"Part 3: Advanced Text Processing - LDA and BERTopic Topic Modeling (20 pts)","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"nlp-p04","title":"Part 4","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"proj02-nlp","title":"Project 2: Reproducibility in Natural Language Processing","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"project-description","title":"Project 2: Reproducibility in Natural Langauge Processing","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1}]}]},"page":{"version":2,"kind":"Notebook","sha256":"8d2300d00a12246fb1f1d35a5c6dc45ddac011643068c2ac098ef94d5fe1cc26","slug":"proj02-nlp","location":"/proj02-nlp.ipynb","dependencies":[],"frontmatter":{"title":"Project 2: Reproducibility in Natural Language Processing","content_includes_title":false,"kernelspec":{"name":"python3","display_name":"Python 3 (ipykernel)","language":"python"},"authors":[{"nameParsed":{"literal":"Reily Fairchild","given":"Reily","family":"Fairchild"},"name":"Reily Fairchild","affiliations":["UC Berkeley"],"id":"contributors-myst-generated-uid-0"},{"nameParsed":{"literal":"Atiila Joselyn Birah Kharobo","given":"Atiila Joselyn Birah","family":"Kharobo"},"name":"Atiila Joselyn Birah Kharobo","affiliations":["UC Berkeley"],"id":"contributors-myst-generated-uid-1"},{"nameParsed":{"literal":"Jordan Elizabeth Collins","given":"Jordan Elizabeth","family":"Collins"},"name":"Jordan Elizabeth Collins","affiliations":["UC Berkeley"],"id":"contributors-myst-generated-uid-2"},{"nameParsed":{"literal":"Aditya Jagannadha Sai Mangalampalli","given":"Aditya Jagannadha Sai","family":"Mangalampalli"},"name":"Aditya Jagannadha Sai Mangalampalli","affiliations":["UC Berkeley"],"id":"contributors-myst-generated-uid-3"}],"github":"https://github.com/UCB-stat-159-f25/proj02-group7","affiliations":[{"id":"UC Berkeley","name":"UC Berkeley"}],"source_url":"https://github.com/UCB-stat-159-f25/proj02-group7/blob/main/proj02-nlp.ipynb","edit_url":"https://github.com/UCB-stat-159-f25/proj02-group7/edit/main/proj02-nlp.ipynb","exports":[{"format":"ipynb","filename":"proj02-nlp.ipynb","url":"/user/jcollins36855/myst-build/proj02-group7/build/proj02-nlp-12c51093153f186e2c49d38ac8ccac40.ipynb"}]},"widgets":{},"mdast":{"type":"root","children":[{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Part 1: Data Loading and Initial Exploration (15 pts)","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"nQKs3JlyH5"}],"identifier":"part-1-data-loading-and-initial-exploration-15-pts","label":"Part 1: Data Loading and Initial Exploration (15 pts)","html_id":"part-1-data-loading-and-initial-exploration-15-pts","implicit":true,"key":"TVUAPfZ25h"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"The data for this project is stored in the ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"nPdEbPAX8S"},{"type":"inlineCode","value":"data","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"TbdLULWTpa"},{"type":"text","value":" folder in your repositories, in the ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"J4391gsLJ9"},{"type":"inlineCode","value":"SOTU.csv","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"jPBwTG7Da6"},{"type":"text","value":" file. The data file is structured as a CSV with columns for president name, speech text, year, and word count in the speech.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"Ibu15xjmWb"}],"key":"n9y9RUMbrV"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"In this section you will:","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"X5XLh1swhr"}],"key":"YeFFDA09hP"},{"type":"list","ordered":true,"start":1,"spread":false,"position":{"start":{"line":7,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Import the data into a pandas dataframe","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"AXVQ4NuRJS"}],"key":"ctQmIBalMU"}],"key":"MZ0p4WAOnh"},{"type":"listItem","spread":true,"position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Perform exploratory data analysis (EDA) including specifically:","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"fxHZ7v80tQ"}],"key":"x7ACha3wSX"}],"key":"ZCG2OC7WWQ"}],"key":"RdTftJDcEF"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":9,"column":1},"end":{"line":13,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Analyze the number of speeches per president","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"t7rdcWazfz"}],"key":"uha1fxuwMc"}],"key":"yjrek6DbTv"},{"type":"listItem","spread":true,"position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Analyze the number of speeches per year","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"zymaUFrNmD"}],"key":"KeOiHauR3m"}],"key":"n4TjZM7N01"},{"type":"listItem","spread":true,"position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Analyze the word count distribution","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"TQZG5Pp8wm"}],"key":"CPPy1eIfhv"}],"key":"wpvFtKukt9"},{"type":"listItem","spread":true,"position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Analyze the word count distribution accross years using a rug plot","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"key":"usdCKzWho5"}],"key":"AvkLuUWc33"}],"key":"jDpk2FT1xP"},{"type":"listItem","spread":true,"position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Analyze the average word count per president","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"fcVjL8AZXV"}],"key":"m4yE5n9AqZ"}],"key":"rPWpfuFgic"}],"key":"VEwa2cbxKA"},{"type":"list","ordered":true,"start":3,"spread":false,"position":{"start":{"line":14,"column":1},"end":{"line":15,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":14,"column":1},"end":{"line":15,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Write commentary on your findings","position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"key":"ml3cJqJTlb"}],"key":"vZU20Lmw8k"}],"key":"l6o3qfi74p"}],"key":"bs6rcnnaoN"},{"type":"paragraph","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"children":[{"type":"text","value":"First, create the ","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"key":"mSxxEZ7VNr"},{"type":"inlineCode","value":"conda","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"key":"fCFgjkqe5R"},{"type":"text","value":" environment with the provided yaml file. Note, it’s not unusual for it to take ~15 minutes for the environment to fully install.","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"key":"oIAoEuRcT1"}],"key":"C6MLXBXav3"}],"key":"Ndef6nPnyj"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Read Data","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"ll8KVRQ1QJ"}],"identifier":"read-data","label":"Read Data","html_id":"read-data","implicit":true,"key":"o8a4AEJlN2"}],"key":"kOqSfemAwu"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# imports\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nplt.style.use('seaborn-v0_8-dark') ","key":"sQiGqrPorN"},{"type":"output","id":"YjOU0jlSz6KB5VllL6l6Z","data":[],"key":"U0PdC8Zt6N"}],"key":"uUDMAZ9fCM"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# read in SOTU.csv using pandas, name the variable `sou` for simplicity\n# the below cell is what the output should look like\nsou = pd.read_csv('data/SOTU.csv')","key":"yX467Omv0I"},{"type":"output","id":"F9QjN43Pzht_Nk_bp-AzS","data":[],"key":"rJbpZ7hpx5"}],"key":"JtnYYBrvIp"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"sou","key":"JLUP6c03eR"},{"type":"output","id":"EewBW1SkcpG5Sz-hBk1XP","data":[],"key":"tM9zJTUJmS"}],"key":"MX5wPr9nQK"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Exploratory Data Analysis","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"qv4bY9uB4y"}],"identifier":"exploratory-data-analysis","label":"Exploratory Data Analysis","html_id":"exploratory-data-analysis","implicit":true,"key":"CBCxRYdBSS"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Replicate the plots below using the hints specified. For each plot, provide some commentary describing the results/anything interesting you might see.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"Jo3eeegUgG"}],"key":"L998JgodM5"}],"key":"D1SCQuh88K"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":4,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Number of Speeches per President","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"QpjNp2w9B2"}],"identifier":"number-of-speeches-per-president","label":"Number of Speeches per President","html_id":"number-of-speeches-per-president","implicit":true,"key":"otu7vuzaHG"}],"key":"fJLpgpgZqk"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Hint - use value_counts() on the President column\n# Hint - sort in order of dataframe\ncounts = sou[\"President\"].value_counts(sort=False)","key":"JCpJS1tCNw"},{"type":"output","id":"NsCtUHvNZyLIdL_ueivnw","data":[],"key":"MwKoYxGWak"}],"key":"RhRGwjqJSq"},{"type":"block","kind":"notebook-code","data":{"scrolled":true},"children":[{"type":"code","lang":"python","executable":true,"value":"# Plot \n# Hint - use the .plot() method for Pandas Series, make sure all presidents show up on x-axis\n\ncounts.plot(kind=\"bar\", figsize=(20, 10))\nplt.title(\"Number of Speeches per President\", fontsize=24)\nplt.xlabel(\"President\", fontsize=18)\nplt.ylabel(\"Count\", fontsize=18)\nplt.xticks(rotation=90, fontsize=13)\nplt.yticks(fontsize=13)\n\nplt.show()","key":"UGmG1iPPXc"},{"type":"output","id":"YKlCok5ILj5orPsDNPu7D","data":[],"key":"uC6DfeMehP"}],"key":"Pl1cQFMjZV"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":4,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Number of Speeches per Year","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"w3XKM8XKxo"}],"identifier":"number-of-speeches-per-year","label":"Number of Speeches per Year","html_id":"number-of-speeches-per-year","implicit":true,"key":"Hdjb69EsTP"}],"key":"b3FIjbGJ0g"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Hint - Use value counts and sort by years\ncounts_by_year = sou[\"Year\"].value_counts().sort_index()\n\nplt.figure(figsize=(5.75, 5))\ncounts_by_year.plot(kind=\"line\")\n\nplt.title(\"Number of State of the Union Speeches per Year\")\nplt.xlabel(\"Year\")\nplt.ylabel(\"Count\")\n\nplt.tight_layout()\nplt.show()","key":"m8oC8mM2Mg"},{"type":"output","id":"YiNbpKw_F5kg7OCnFiTgo","data":[],"key":"nGKWNpkErK"}],"key":"JvFb2IoFIf"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":4,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Word Count Distribution","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Ali9O9RoIL"}],"identifier":"word-count-distribution","label":"Word Count Distribution","html_id":"word-count-distribution","implicit":true,"key":"AyW8g7g83D"}],"key":"PSYhTDw8JE"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Hint - try seaborn.histplot()\n\nplt.figure(figsize=(5.75, 5))\n\nsns.histplot(\n    sou[\"Word Count\"],\n    bins=18,\n    kde=False,\n    color=\"steelblue\"\n)\n\nplt.title(\"Distribution of State of the Union Speech\\nWord Counts\")\nplt.xlabel(\"Word Count\")\nplt.ylabel(\"Count\")\n\nplt.tight_layout()\nplt.show()","key":"AAYOaFrRvb"},{"type":"output","id":"y74_8_0L6BYf9KVuPI0M3","data":[],"key":"pf45BxF8Z7"}],"key":"OtLIiiNAU2"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":4,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Word Count Distribution over Year","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Uk09N1T64R"}],"identifier":"word-count-distribution-over-year","label":"Word Count Distribution over Year","html_id":"word-count-distribution-over-year","implicit":true,"key":"qOhxARCQgT"}],"key":"rlz5OTB7h5"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Hint: try seaborn.rugplot()\nplt.figure(figsize=(6, 5))\n\nsns.scatterplot(\n    data=sou,\n    x=\"Word Count\",\n    y=\"Year\",\n    s=40\n)\n\nsns.rugplot(\n    data=sou,\n    x=\"Word Count\",\n    height=0.02,\n    alpha=0.6,\n)\n\nsns.rugplot(\n    data=sou,\n    y=\"Year\",\n    height=0.02,\n    alpha=1,\n    color=(59/255, 117/255, 174/255)\n)\n\nplt.title(\"Speech Year Versus Word Count\")\nplt.xlabel(\"Word Count\")\nplt.ylabel(\"Year\")\n\nplt.tight_layout()\nplt.show()","key":"mvrUJw2d21"},{"type":"output","id":"SVW8N4clc9JRYXrOcRvu1","data":[],"key":"IGbSpddsPT"}],"key":"JMZ1u2qzKm"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":4,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Word Count Distribution per President","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"yljC9pZsBo"}],"identifier":"word-count-distribution-per-president","label":"Word Count Distribution per President","html_id":"word-count-distribution-per-president","implicit":true,"key":"E07IrNjBbH"}],"key":"IFFIJvQbG7"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Hint: use pandas groupby to get mean word count per president then sort by order\n\navg_words = sou.groupby(\"President\")[\"Word Count\"].mean()\n\navg_words = avg_words.loc[sou[\"President\"].unique()]\nplt.figure(figsize=(10, 6))\navg_words.plot(kind=\"bar\")\n\nplt.title(\"Average State of the Union Word Count\\nper President\")\nplt.xlabel(\"President\")\nplt.ylabel(\"Average Word Count\")\n\nplt.xticks(rotation=90)\nplt.tight_layout()\nplt.show()","key":"XUBZ9qPj9c"},{"type":"output","id":"ZLeaLPNgHoQviP6d9RAbg","data":[],"key":"q7HKmFW5fv"}],"key":"DGFKFEgDQr"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Part 2: Simple Text Processing - Tokenization, Lemmatization, Word Frequency, Vectorization (20 pts)","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"leFJzgkVfY"}],"identifier":"part-2-simple-text-processing-tokenization-lemmatization-word-frequency-vectorization-20-pts","label":"Part 2: Simple Text Processing - Tokenization, Lemmatization, Word Frequency, Vectorization (20 pts)","html_id":"part-2-simple-text-processing-tokenization-lemmatization-word-frequency-vectorization-20-pts","implicit":true,"key":"jHIJLWHkQh"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Now we will start working on simple text processing using the ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"i7g4TXIuRa"},{"type":"inlineCode","value":"SpaCy","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"gMbp3yo9vk"},{"type":"text","value":" package and the same dataset as Part 1. The package should already be included in the ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"wZpp18dN7l"},{"type":"inlineCode","value":"environment.yml","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"XpK08jwU2Y"},{"type":"text","value":". However, we will also need to download ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"gaHyHDKoLE"},{"type":"inlineCode","value":"en_core_web_sm","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"u4hwqbose9"},{"type":"text","value":", an English language text processing model. To do this, while having your ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"FEUwpi3p5J"},{"type":"inlineCode","value":"sotu","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"De2wB2UkDm"},{"type":"text","value":" environment activated, run the following:","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"tcgdxs4mVW"}],"key":"n7OLMBptFf"},{"type":"code","lang":"","value":"python -m spacy download en_core_web_sm","position":{"start":{"line":5,"column":1},"end":{"line":7,"column":1}},"key":"Ok2YWs564Z"},{"type":"paragraph","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"Now, you should be good to go!","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"RuIdXxYzWF"}],"key":"JWrPMCBFZP"},{"type":"paragraph","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"text","value":"Some important definitions:","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"hn9GrsSvwp"}],"key":"pmYXhhgyxq"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":13,"column":1},"end":{"line":17,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"children":[{"type":"paragraph","children":[{"type":"emphasis","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"children":[{"type":"text","value":"Token","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"qxALWm5nJq"}],"key":"wJXduAoL9x"},{"type":"text","value":": a single word or piece of a word","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"FPPru8ZekJ"}],"key":"x8o01dNy8G"}],"key":"ZszimovRuQ"},{"type":"listItem","spread":true,"position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"children":[{"type":"paragraph","children":[{"type":"emphasis","position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"children":[{"type":"text","value":"Lemma","position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"key":"qDPXl9uvwl"}],"key":"tpX3jNuO0x"},{"type":"text","value":": the core component of a word, e.g., “complete” is the lemma for “completed” and “completely”","position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"key":"nSxSYUuH1i"}],"key":"PKieJ3E063"}],"key":"yZm8zkQk6j"},{"type":"listItem","spread":true,"position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"children":[{"type":"paragraph","children":[{"type":"emphasis","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"children":[{"type":"text","value":"Stop Word","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"d1MYowq63A"}],"key":"Tmcb7hXO34"},{"type":"text","value":": a common word that does not add semantic value, such as “a”, “and”, “the”, etc.","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"tqC0rc1H0s"}],"key":"GLk9zcxGAW"}],"key":"HTsfn2EHCW"},{"type":"listItem","spread":true,"position":{"start":{"line":16,"column":1},"end":{"line":17,"column":1}},"children":[{"type":"paragraph","children":[{"type":"emphasis","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"children":[{"type":"text","value":"Vectorization","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"key":"Lm6xUOGma4"}],"key":"br7YvrQmYp"},{"type":"text","value":": representing a document as a vector where each index in the vector corresponds to a token or word and each entry is the count.","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"key":"n8EYNzyTAx"}],"key":"sx5SOMPkBS"}],"key":"QecDZSYRBs"}],"key":"qkYcuUvoGw"},{"type":"paragraph","position":{"start":{"line":18,"column":1},"end":{"line":18,"column":1}},"children":[{"type":"text","value":"In this section, we will explore the most common tokens and lemmas throughout different slices of the speech data. We will also develop vectorization representations of the speeches.","position":{"start":{"line":18,"column":1},"end":{"line":18,"column":1}},"key":"Hu4iMWqR3A"}],"key":"xvpedvszpc"},{"type":"paragraph","position":{"start":{"line":20,"column":1},"end":{"line":20,"column":1}},"children":[{"type":"text","value":"The core steps are:","position":{"start":{"line":20,"column":1},"end":{"line":20,"column":1}},"key":"MslscsTgNE"}],"key":"PsIi5hMNem"},{"type":"list","ordered":true,"start":1,"spread":false,"position":{"start":{"line":22,"column":1},"end":{"line":23,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":22,"column":1},"end":{"line":22,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Process speeches using the SpaCy nlp module","position":{"start":{"line":22,"column":1},"end":{"line":22,"column":1}},"key":"wSDT0iJGUg"}],"key":"FMIPkEiALM"}],"key":"XaZ8EekhTL"},{"type":"listItem","spread":true,"position":{"start":{"line":23,"column":1},"end":{"line":23,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Analyze Tokens vs Lemmas:","position":{"start":{"line":23,"column":1},"end":{"line":23,"column":1}},"key":"oPWAlf6qq0"}],"key":"SztZ73IG5f"}],"key":"KA8f9fRKAX"}],"key":"bXVaFMxpiU"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":24,"column":1},"end":{"line":26,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":24,"column":1},"end":{"line":24,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Create a list of all tokens across all speeches that are not stop words, punctuation, or spaces.","position":{"start":{"line":24,"column":1},"end":{"line":24,"column":1}},"key":"QofrAb4XJv"}],"key":"RoZz582sse"}],"key":"IB1yAKG7Zb"},{"type":"listItem","spread":true,"position":{"start":{"line":25,"column":1},"end":{"line":25,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Create a second list of the lemmas for these same tokens.","position":{"start":{"line":25,"column":1},"end":{"line":25,"column":1}},"key":"EN8o6gTYYx"}],"key":"mMiPhr9kwD"}],"key":"SpH6uoEppk"},{"type":"listItem","spread":true,"position":{"start":{"line":26,"column":1},"end":{"line":26,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Display the top 25 for each of these and compare.","position":{"start":{"line":26,"column":1},"end":{"line":26,"column":1}},"key":"dx87pCloyx"}],"key":"aadusFIT6V"}],"key":"kubJ5n0NN1"}],"key":"Q5VUKIUO05"},{"type":"list","ordered":true,"start":3,"spread":false,"position":{"start":{"line":27,"column":1},"end":{"line":27,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":27,"column":1},"end":{"line":27,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Analyze common word distributions over different years:","position":{"start":{"line":27,"column":1},"end":{"line":27,"column":1}},"key":"rdPzQnKgy0"}],"key":"dcPqjTk2E7"}],"key":"kYuiCT2xPz"}],"key":"SM0Mg1lxXb"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":28,"column":1},"end":{"line":29,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":28,"column":1},"end":{"line":28,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Create a function that takes the dataset and a year as an input and outputs the top n lemmas for that year’s speeches","position":{"start":{"line":28,"column":1},"end":{"line":28,"column":1}},"key":"Kw7OM1rNJw"}],"key":"P3UZCCUUZ2"}],"key":"Ke4WmZbKCs"},{"type":"listItem","spread":true,"position":{"start":{"line":29,"column":1},"end":{"line":29,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Compare the top 10 words for 2023 versus 2019","position":{"start":{"line":29,"column":1},"end":{"line":29,"column":1}},"key":"lfp58M4r5z"}],"key":"zQ8xwsLqIL"}],"key":"VynoMA0D9v"}],"key":"WVhLU2aGMu"},{"type":"list","ordered":true,"start":4,"spread":false,"position":{"start":{"line":30,"column":1},"end":{"line":30,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":30,"column":1},"end":{"line":30,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Document Vectorization:","position":{"start":{"line":30,"column":1},"end":{"line":30,"column":1}},"key":"e37ngQjqgt"}],"key":"xUlmHcyc4E"}],"key":"YtUWoyg7Pb"}],"key":"aaYNuzTFCZ"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":31,"column":1},"end":{"line":33,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":31,"column":1},"end":{"line":31,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Train a Term Frequency-Inverse Document Frequency (TF-IDF) vectorization model using your processed dataset and scikit learn","position":{"start":{"line":31,"column":1},"end":{"line":31,"column":1}},"key":"f7w3sPnXPy"}],"key":"J2ChsFeCIL"}],"key":"y2qvBOUZh6"},{"type":"listItem","spread":true,"position":{"start":{"line":32,"column":1},"end":{"line":33,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Output the feature vectors","position":{"start":{"line":32,"column":1},"end":{"line":32,"column":1}},"key":"qfqtOIyrBU"}],"key":"wTsMLJKpKo"}],"key":"uMBymVzctw"}],"key":"I7sKmXFoVo"},{"type":"paragraph","position":{"start":{"line":34,"column":1},"end":{"line":34,"column":1}},"children":[{"type":"strong","position":{"start":{"line":34,"column":1},"end":{"line":34,"column":1}},"children":[{"type":"text","value":"Helpful Resources:","position":{"start":{"line":34,"column":1},"end":{"line":34,"column":1}},"key":"PQ9cu4c0TA"}],"key":"nRa1pUwLvd"}],"key":"IQUfGgr6AA"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":35,"column":1},"end":{"line":39,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":35,"column":1},"end":{"line":35,"column":1}},"children":[{"type":"paragraph","children":[{"type":"link","url":"https://realpython.com/natural-language-processing-spacy-python/","position":{"start":{"line":35,"column":1},"end":{"line":35,"column":1}},"children":[{"type":"text","value":"https://​realpython​.com​/natural​-language​-processing​-spacy​-python/","position":{"start":{"line":35,"column":1},"end":{"line":35,"column":1}},"key":"De8KXrv8ft"}],"urlSource":"https://realpython.com/natural-language-processing-spacy-python/","key":"v7sOZ7G48R"}],"key":"WqPVqJS7uS"}],"key":"a17e642fwJ"},{"type":"listItem","spread":true,"position":{"start":{"line":36,"column":1},"end":{"line":36,"column":1}},"children":[{"type":"paragraph","children":[{"type":"link","url":"https://www.statology.org/text-preprocessing-feature-engineering-spacy/","position":{"start":{"line":36,"column":1},"end":{"line":36,"column":1}},"children":[{"type":"text","value":"https://​www​.statology​.org​/text​-preprocessing​-feature​-engineering​-spacy/","position":{"start":{"line":36,"column":1},"end":{"line":36,"column":1}},"key":"ITIeYTwUoH"}],"urlSource":"https://www.statology.org/text-preprocessing-feature-engineering-spacy/","key":"AmDggSbPJP"}],"key":"eCbfvS7bua"}],"key":"FKAguo2xsp"},{"type":"listItem","spread":true,"position":{"start":{"line":37,"column":1},"end":{"line":37,"column":1}},"children":[{"type":"paragraph","children":[{"type":"link","url":"https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html#","position":{"start":{"line":37,"column":1},"end":{"line":37,"column":1}},"children":[{"type":"text","value":"https://​scikit​-learn​.org​/stable​/modules​/generated​/sklearn​.feature​_extraction​.text​.TfidfVectorizer​.html#","position":{"start":{"line":37,"column":1},"end":{"line":37,"column":1}},"key":"HUWC0NDHi8"}],"urlSource":"https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html#","key":"omZfXbBtR8"}],"key":"a75gqcjIDb"}],"key":"Sx0V8oBQWe"},{"type":"listItem","spread":true,"position":{"start":{"line":38,"column":1},"end":{"line":39,"column":1}},"children":[{"type":"paragraph","children":[{"type":"link","url":"https://www.geeksforgeeks.org/nlp/how-to-store-a-tfidfvectorizer-for-future-use-in-scikit-learn/","position":{"start":{"line":38,"column":1},"end":{"line":38,"column":1}},"children":[{"type":"text","value":"https://​www​.geeksforgeeks​.org​/nlp​/how​-to​-store​-a​-tfidfvectorizer​-for​-future​-use​-in​-scikit​-learn/","position":{"start":{"line":38,"column":1},"end":{"line":38,"column":1}},"key":"CmLUIQvBcw"}],"urlSource":"https://www.geeksforgeeks.org/nlp/how-to-store-a-tfidfvectorizer-for-future-use-in-scikit-learn/","key":"raSpDkR5e8"}],"key":"S6HSVQs8rs"}],"key":"Liqyd7Zo7h"}],"key":"iKIhW8Tu0r"}],"key":"zKurezoQAm"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Processing Speeches with SpaCy","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"hKwua6W4ps"}],"identifier":"processing-speeches-with-spacy","label":"Processing Speeches with SpaCy","html_id":"processing-speeches-with-spacy","implicit":true,"key":"UbeavFX4YN"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Lets study just speeches from 2000 and onwards to begin with. So, be sure to subset your DataFrame to just these speeches before continuing!","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"xT71Fr2tEq"}],"key":"YCkFMNnoLT"}],"key":"lSIe7UR8pG"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"import spacy\nfrom tqdm import tqdm\nfrom collections import Counter\n\nnlp = spacy.load(\"en_core_web_sm\")","key":"x1fGufnUUi"},{"type":"output","id":"rowR77LM9xC30OfPHINuU","data":[],"key":"J3UQN8iHzS"}],"key":"uPS4nk89l1"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"sou_new = sou[sou['Year'] \u003e= 2000]\nsou_new","key":"i5SomRrco8"},{"type":"output","id":"s6iTfy66Rgs0mV6C4LUVF","data":[],"key":"xx1XMrZRcM"}],"key":"kzhzhnm7Vn"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"processed_speeches = []\n\nfor i in range(len(sou_new)):\n    speech_text = sou_new.loc[i, 'Text'] \n    processed = nlp(speech_text)    \n    processed_speeches.append(processed)\n","key":"Irf8TxEloK"},{"type":"output","id":"b5L0KmMZHI1wpmLmECN5N","data":[],"key":"ikTQzeAnru"}],"key":"MTVhpRdgm4"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"","key":"meAbQwnRwE"},{"type":"output","id":"R69WQ2DUaf-I0KCazzypf","data":[],"key":"EnSDWTLtGB"}],"key":"ha9s8C7xg9"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Analyze Tokens vs Lemmas","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"fczTe5TVXb"}],"identifier":"analyze-tokens-vs-lemmas","label":"Analyze Tokens vs Lemmas","html_id":"analyze-tokens-vs-lemmas","implicit":true,"key":"cLNr9virkz"},{"type":"heading","depth":4,"position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Token List","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"CK5D3blB8t"}],"identifier":"token-list","label":"Token List","html_id":"token-list","implicit":true,"key":"aSBIA2Ek8V"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"Create a list of tokens across all speeches that are not spaces, stopwords, or punctuation. Make each token lowercase as well. ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"qU7ch2k0Mh"},{"type":"emphasis","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"Hint: each element of the list we just created are themselves lists of tokens. Token objects have attributes ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"IpgzBfEe1Y"},{"type":"inlineCode","value":"is_stop","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"niWUbW7Sz6"},{"type":"text","value":", ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"WecvWDD9J6"},{"type":"inlineCode","value":"is_punct","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"Ii7MRPavwk"},{"type":"text","value":", and ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"VqOACqt5hY"},{"type":"inlineCode","value":"is_space","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"NeqQA3efI1"},{"type":"text","value":".","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"YduPbWPwNy"}],"key":"K7esHGAZxm"}],"key":"BZ811OD8fn"}],"key":"c8zCFpaKqB"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"tokens = []\n\nfor speech in processed_speeches:\n    for token in speech:\n        if not token.is_punct and not token.is_space and not token.is_stop:\n            tokens.append(token.text.lower())\n\n","key":"AL3IoyG4zu"},{"type":"output","id":"3Rkj9bAIOdQEDa8z-lP6F","data":[],"key":"PrZhJqGqc0"}],"key":"N28xoEDDKq"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# print top 20 tokens\ntoken_counts = Counter(tokens).most_common(20)\ntoken_counts\n","key":"Fc8GhkzvcW"},{"type":"output","id":"xeM8Ub_nFsDC1lryVArWR","data":[],"key":"f6y8WHXSiJ"}],"key":"VmRq7EDiUQ"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":4,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Lemma List","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"iAAmUNmfp1"}],"identifier":"lemma-list","label":"Lemma List","html_id":"lemma-list","implicit":true,"key":"i5fFVMY1fD"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Do the same as above, but for lemmas. ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"A0eVttx86H"},{"type":"emphasis","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Hint: recall lemmas are components of words. Each token should have an attribute to extract the lemma.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"P09bhdb2wJ"}],"key":"YwS6gZtws8"}],"key":"FPMuJFyDLs"}],"key":"sdmgoo4dKC"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"lemmas = []\n\nfor word in tokens:\n    doc = nlp(word)  \n    for token in doc:\n        lemmas.append(token.lemma_.lower())\n","key":"BiAdIItnrN"},{"type":"output","id":"O1Ly3b9HsyaJKQooFwSet","data":[],"key":"AuQQrOBNRa"}],"key":"oNwy3SPnWX"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# print top 20 lemmas\nlemma_counts = Counter(lemmas).most_common(20)\nlemma_counts","key":"NMlLAAlb7H"},{"type":"output","id":"pHfFzU8dQqqbyJ_vBjBwH","data":[],"key":"qtcj7GaeNb"}],"key":"BW0svAfM3m"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":4,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Token versus Lemma Comparison","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"mXN2RI2Yeu"}],"identifier":"token-versus-lemma-comparison","label":"Token versus Lemma Comparison","html_id":"token-versus-lemma-comparison","implicit":true,"key":"Pyv0SHaGoY"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"What do you notice about the top tokens versus the top lemmas?\nConsider two tokens - “year” and “years” - how do their counts compare to the lemma “year”?\nWhat about the lemma “child”?","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"VvgX7PNgeJ"}],"key":"N3pZQj4ytD"}],"key":"VlG8jit8lL"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"Tokens ‘years’ and ‘year’ are common tokens, appearing in the 5th and 7th most common slots, respectively. The lemma ‘year’\nis the most popular lemma and its occurance is the sum of the occurences of its similar tokens. Although ‘child’ does not appear in the top 20 tokens, it does appear as the 17th most common lemma. This could be becuase there are many tokens related to the lemma ‘child’ such as ‘child,’ ‘children,’ ‘childish,’ and ‘childrens’.’ This is twice the amount of tokens related to the same lemma of ‘child’ as there is for the lemma of ‘year.’","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"bVXL30DPcW"}],"key":"BOyJ1uj0pi"}],"key":"naGyUn39tD"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Common Words","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"hDfUcAn9tM"}],"identifier":"common-words","label":"Common Words","html_id":"common-words","implicit":true,"key":"CZtYjFEeRT"},{"type":"heading","depth":4,"position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Common Words per Year Function","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"vFggw3BiWx"}],"identifier":"common-words-per-year-function","label":"Common Words per Year Function","html_id":"common-words-per-year-function","implicit":true,"key":"UHS9T2kV8l"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"Fill in the below function to obtain the n-most common words in speeches for a given year.","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"wdqP2zF5Aq"}],"key":"yfRnaAD6Vf"},{"type":"paragraph","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"inputs:","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"CGETyKjvQv"}],"key":"zE76qSW1AW"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":8,"column":1},"end":{"line":13,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"df raw unprocessed sou dataframe","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"NkNfjNYfVf"}],"key":"ak2gbGFfJT"}],"key":"YxWd5YELhx"},{"type":"listItem","spread":true,"position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"year","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"GHWR1Tv7Q3"}],"key":"tCVtxeC00n"}],"key":"YilFGhPrOF"},{"type":"listItem","spread":true,"position":{"start":{"line":10,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"n\noutputs:","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"VW7B67VO4p"}],"key":"rp054s6WR8"}],"key":"xjlodYOkcm"},{"type":"listItem","spread":true,"position":{"start":{"line":12,"column":1},"end":{"line":13,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"top n words for that years","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"key":"A7UlvWx6ap"}],"key":"IFNzuUmy5X"}],"key":"kTbylhSWKM"}],"key":"AkiI5PC37Z"},{"type":"paragraph","position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"children":[{"type":"text","value":"steps:","position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"key":"RlRvcovaZ9"}],"key":"felgM5RISg"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":15,"column":1},"end":{"line":18,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"subset the dataframe for the year of interest - note the years might not be in int type","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"ue7boOTzyH"}],"key":"EUfDj98CFK"}],"key":"J7SsOGkiih"},{"type":"listItem","spread":true,"position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"process the subsetted dataframe with spacy","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"key":"Dd8qmEZimg"}],"key":"BvcieoDUcu"}],"key":"f3hlq2YPNh"},{"type":"listItem","spread":true,"position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"get the lemmas across all those speeches","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"key":"X9NTO3UmhS"}],"key":"siTnpCncEf"}],"key":"OPAuo6Zwsr"},{"type":"listItem","spread":true,"position":{"start":{"line":18,"column":1},"end":{"line":18,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"count the top n lemmas","position":{"start":{"line":18,"column":1},"end":{"line":18,"column":1}},"key":"y8fFQKy1rz"}],"key":"voCK5Ja89Z"}],"key":"UlHma1EbjU"}],"key":"rttIMPqq6w"}],"key":"w0MqGb1TBH"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"def get_most_common_words(df, year, n=25):\n    \"\"\"\n    Processes the SOTU speech for a given year and returns\n    the most common non-stopword/punctuation lemmas.\n\n    INPUTS\n    - raw unprocessed sou data frame\n    - year\n\n    OUTPUTS\n    - top n words for that year\n    \"\"\"\n\n    # Step 1: Subset df\n    new_df = df[df['Year'] == year]\n    \n    # Step 2: Process the text with spaCy\n    new_df = df[df['Year'] == year].reset_index(drop=True) \n    processed_speeches = []\n\n    for i in range(len(new_df)):\n        speech_text = new_df.loc[i, 'Text'] \n        processed = nlp(speech_text)    \n        processed_speeches.append(processed)\n    \n    # Step 3: Get lemmas\n    lemmas = []\n\n    for doc in processed_speeches:\n        for token in doc:\n            if not token.is_punct and not token.is_space and not token.is_stop:\n                lemmas.append(token.lemma_.lower())\n    \n    lemma_counts = Counter(lemmas).most_common(n)\n    \n    return lemma_counts","key":"MNpNjXUwuA"},{"type":"output","id":"oqwMpFeeqBbl49letxr0W","data":[],"key":"M8PsFHraWr"}],"key":"v1VEsxTTkJ"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# test it on 2024\nget_most_common_words(sou, 2024, n=20)","key":"dLeeXAECO2"},{"type":"output","id":"h_Yhh3NFKZwsBmhjCDrg3","data":[],"key":"ZCAxeroD6b"}],"key":"DDu8GfRACO"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":4,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Compare 2023 to 2017","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"PzGbwS1M4B"}],"identifier":"compare-2023-to-2017","label":"Compare 2023 to 2017","html_id":"compare-2023-to-2017","implicit":true,"key":"J4ITRFkh8S"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Run your function from the previous step to get the top 20 words for 2017 and 2023. Plot the words and their frequencies in a barchart and replicate the figure below.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"P0Xmc0zRhB"}],"key":"RS3yYhbPdN"}],"key":"vKkM326Z98"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"words_2023 = get_most_common_words(sou, 2023, n=20)\nwords_2017 = get_most_common_words(sou, 2017, n=20)","key":"V4k5OU1kMk"},{"type":"output","id":"FdrA1HfKTDkT8CmG_Kc_j","data":[],"key":"hiJtetPsip"}],"key":"An95TyGvNi"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"words_2023","key":"d7wpZc5Tvv"},{"type":"output","id":"UU2keyLdoA2vG7xL84I6c","data":[],"key":"ieHyyyAsS8"}],"key":"Gf01Mhf86y"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"words_2017","key":"X5xAhkMt7m"},{"type":"output","id":"JntGXAywBjr2hbj1RTXYG","data":[],"key":"O2fTQZvErj"}],"key":"Q2MFkImdEH"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Hint - put the words and counts into a pd Dataframe for better structure\n# and to make plotting easier\ndf_2017 = pd.DataFrame(words_2017, columns=['lemma', 'count'])\ndf_2023 = pd.DataFrame(words_2023, columns=['lemma', 'count'])","key":"T0PYGldI4c"},{"type":"output","id":"Q27LwwfBPgu5qBqeheAxi","data":[],"key":"p1TMUbQvSe"}],"key":"xFuw5qsnHl"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Hint - use seaborn, subplots, and rotate tick labels\n\nfig, axes = plt.subplots(2, 1, figsize=(12, 10)) \n# Plot 2017\nsns.barplot(\n    x = 'lemma',\n    y = 'count',\n    data = df_2017,\n    ax = axes[0],\n     color='#2C7BA1'\n    \n)\naxes[0].set_title('2017 State of the Union Most Frequent Words')\naxes[0].set_xlabel('Word')\naxes[0].set_ylabel('Count')\naxes[0].tick_params(axis='x', rotation=45) \n\n# Plot 2023\nsns.barplot(\n    x='lemma',\n    y='count',\n    data=df_2023,\n    ax=axes[1],\n    color='#2C7BA1'\n)\n\naxes[1].set_title('2023 State of the Union Most Frequent Words')\naxes[1].set_xlabel('Word')\naxes[1].set_ylabel('Count')\naxes[1].tick_params(axis='x', rotation=45)\n\nplt.tight_layout()","key":"AKmEyBvtHa"},{"type":"output","id":"5gbWgp0RWmwgvMUaIF8Mz","data":[],"key":"VGaxcjolvT"}],"key":"pEQVnH1PjU"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"TF-IDF Vectorization","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"WGW65ZT0HG"}],"identifier":"tf-idf-vectorization","label":"TF-IDF Vectorization","html_id":"tf-idf-vectorization","implicit":true,"key":"VBWGEDrbPB"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"To use statsitical alorithms on documents, we need to transform them into vectors, where each element of the vector corresponds to a particular word in a document or corpus of documents. One common way is via TF-IDF embeddings. LLMs work similarly - they typically use transformer models to generate text embeddings before sending text through a deep neural network.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"CMvmx2a3Tu"}],"key":"RFGgKJLdhN"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"Here we will fit a TF-IDF vectorizer, plot all the speeches on a 2-D grid using PCA and also using a heatmap, and examine TF-IDF scores for the top 10 most common words in the first speech. This is a good resource here: ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"yjWnpfM9EE"},{"type":"link","url":"https://medium.com/GeoffreyGordonAshbrook/vector-visualization-2d-plot-your-tf-idf-with-pca-83fa9fccb1d","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"https://​medium​.com​/GeoffreyGordonAshbrook​/vector​-visualization​-2d​-plot​-your​-tf​-idf​-with​-pca​-83fa9fccb1d","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"Yfr9HVhxPs"}],"urlSource":"https://medium.com/GeoffreyGordonAshbrook/vector-visualization-2d-plot-your-tf-idf-with-pca-83fa9fccb1d","key":"YQrnWo3Bau"}],"key":"AEPYz6xlQL"}],"key":"mscNPp7UYx"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.decomposition import PCA","key":"XlzKd1XL14"},{"type":"output","id":"rHpfaPh8CJAOMTWvFIZbV","data":[],"key":"jajnbOFDCk"}],"key":"KgbJvJbYOX"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":4,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Train the Vectorizer and Transform the Data","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"leaxA7xy2g"}],"identifier":"train-the-vectorizer-and-transform-the-data","label":"Train the Vectorizer and Transform the Data","html_id":"train-the-vectorizer-and-transform-the-data","implicit":true,"key":"FJjNUBxXTr"}],"key":"Hg79cght60"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# you may use this as input to fit the TF-IDF vectorizer\nraw_docs = sou[\"Text\"].to_list()","key":"Dk7eeb4ATc"},{"type":"output","id":"Fox36X2GWY6TsT7vNDyD_","data":[],"key":"tRESaRPWck"}],"key":"G6r4M6anl8"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Hint - use fit_transform for vectorizer and PCA","key":"p94YvDBx0Q"},{"type":"output","id":"VqJtHpoAZgGyqjWslqEjr","data":[],"key":"DP33Btf5Ux"}],"key":"ZLkwmCwjoK"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"The output of ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"gY58xsR5rb"},{"type":"inlineCode","value":"fit_transform()","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"t9oXIovAOa"},{"type":"text","value":" will be a matrix where each row corresponds to a speech, each column corresponds to a word in the corpus of speeches, and the value is the TF-IDF score which measures the importance of that word in that speech, relative to the rest of the speeches.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"vjovLwjcdl"}],"key":"ruYE8XtJSl"}],"key":"YgUpyTes0l"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":4,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Plot Speeches","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"ej4CxMW5AK"}],"identifier":"plot-speeches","label":"Plot Speeches","html_id":"plot-speeches","implicit":true,"key":"tKh6jQfwh2"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":3,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"First used PCA to generate the first chart","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"pWl6YqVGlo"}],"key":"j82odkugQh"}],"key":"Hkry85ItWR"},{"type":"listItem","spread":true,"position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Second use seaborn heatmap with a log-scaled color axis to generate the second chart","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"wE38SFuYU1"}],"key":"hTi1367dpr"}],"key":"PGNWEtyam1"}],"key":"cdvAy8SbtQ"}],"key":"aIO90y9hxe"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Step 1: Set PCA to find first 2 principal components\n\n# Step 2: Create a new dataframe where each row is a speech, and each column is a projection onto\n# one of the two principal components\n\n# Plot Data Visualization (Matplotlib)","key":"YQWv2WrV6r"},{"type":"output","id":"ZOKirdSFGHaoUd3EM81zJ","data":[],"key":"dfz4sTWjFi"}],"key":"HWDw0nVqyi"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Hint - vectorized_docs is a sparse matrix whose rows are speeches and columns are tokens, with each\n# value being a TF-IDF score. Densify this array first, and then plot using seaborn.","key":"VQNRePf2ev"},{"type":"output","id":"RcpN7yAMALL7DF7AN0Dw_","data":[],"key":"uzRkzV6Dug"}],"key":"kghYVWRMZj"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":4,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Get the TF-IDF value for certain words and documents","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"gwIFAnoqaD"}],"identifier":"get-the-tf-idf-value-for-certain-words-and-documents","label":"Get the TF-IDF value for certain words and documents","html_id":"get-the-tf-idf-value-for-certain-words-and-documents","implicit":true,"key":"FIWlsAQaUx"}],"key":"v44VPqJMP0"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"word_list = ['year',\n 'america',\n 'people',\n 'american',\n 'work',\n 'new',\n 'job',\n 'country',\n 'americans',\n 'world'] # top ten most common words through whole corpus","key":"ODtEBWSvoO"},{"type":"output","id":"b74jW-oUdzg2xFVCjdMi6","data":[],"key":"azg2E3B3Ng"}],"key":"PRmpmd6lTk"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"word_nums = ... # get each word's index number using the .vocabular_ attributed of vectorizer","key":"zMYzdS4c83"},{"type":"output","id":"2hOgwGitLjt74cJy29BhL","data":[],"key":"WusUSh27OO"}],"key":"PZoQdfzjDT"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"idf_score = ... # get their IDF score by using .idf_ at the indices from the previous step","key":"wURk3KVbow"},{"type":"output","id":"vKY9-CJBPwpkoY4akp4vs","data":[],"key":"uIxGg4KXYz"}],"key":"OKEnWqcFZk"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"tf_idf = ... # get the tf_idf score for the first speech","key":"n4vnLsracw"},{"type":"output","id":"UIKzPCV6RWPeQTUDZxLjm","data":[],"key":"E1aNSVmlG2"}],"key":"yHYtIsRs26"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"pd.DataFrame({\"Word\": word_list, \"IDF Score\": idf_score, \"TF-IDF Score\": tf_idf})","key":"CQxhIt5DY8"},{"type":"output","id":"A10ge9uxry98JB-C9HGRQ","data":[],"key":"URNDWMdVEC"}],"key":"wrVzTupQIC"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Part 3: Advanced Text Processing - LDA and BERTopic Topic Modeling (20 pts)","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"ejaSbDRlAM"}],"identifier":"part-3-advanced-text-processing-lda-and-bertopic-topic-modeling-20-pts","label":"Part 3: Advanced Text Processing - LDA and BERTopic Topic Modeling (20 pts)","html_id":"part-3-advanced-text-processing-lda-and-bertopic-topic-modeling-20-pts","implicit":true,"key":"w9oRk49AgE"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"strong","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Resources:","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"aL3wwnJXfz"}],"key":"xxpRTOgpYo"}],"key":"hUbqKmdrWV"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":4,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":4,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"LDA:","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"D6INoGBRT7"}],"key":"ztPJgT9WMF"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":5,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"paragraph","children":[{"type":"link","url":"https://medium.com/sayahfares19/text-analysis-topic-modelling-with-spacy-gensim-4cd92ef06e06","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"https://​medium​.com​/sayahfares19​/text​-analysis​-topic​-modelling​-with​-spacy​-gensim​-4cd92ef06e06","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"w8ldj7oWZs"}],"urlSource":"https://medium.com/sayahfares19/text-analysis-topic-modelling-with-spacy-gensim-4cd92ef06e06","key":"BEIhasIBlX"}],"key":"wTQOOfP3kr"}],"key":"hfOJjve0h0"},{"type":"listItem","spread":true,"position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"paragraph","children":[{"type":"link","url":"https://www.kaggle.com/code/faressayah/text-analysis-topic-modeling-with-spacy-gensim#%F0%9F%93%9A-Topic-Modeling","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"text","value":"https://​www​.kaggle​.com​/code​/faressayah​/text​-analysis​-topic​-modeling​-with​-spacy​-gensim​#📚​-Topic​-Modeling","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"tT6RSq7DK7"}],"urlSource":"https://www.kaggle.com/code/faressayah/text-analysis-topic-modeling-with-spacy-gensim#%F0%9F%93%9A-Topic-Modeling","key":"bLsLPeb9rs"},{"type":"text","value":" (code for previous post)","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"r6cy83tfqC"}],"key":"adNc0DBtM0"}],"key":"Uv3LxvUBuk"},{"type":"listItem","spread":true,"position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"paragraph","children":[{"type":"link","url":"https://towardsdatascience.com/topic-modelling-in-python-with-spacy-and-gensim-dc8f7748bdbf/","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"https://​towardsdatascience​.com​/topic​-modelling​-in​-python​-with​-spacy​-and​-gensim​-dc8f7748bdbf/","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"Y0WplUlZte"}],"urlSource":"https://towardsdatascience.com/topic-modelling-in-python-with-spacy-and-gensim-dc8f7748bdbf/","key":"FEH3nHCDGL"}],"key":"EAz7QcMLfC"}],"key":"z4iUJWigY3"}],"key":"PYUM0AClUE"}],"key":"Hzkc8n7Dvi"},{"type":"listItem","spread":true,"position":{"start":{"line":8,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"BERTopic:","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"FXqcuXUJFr"}],"key":"AxJqjZ0hea"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":9,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"paragraph","children":[{"type":"link","url":"https://maartengr.github.io/BERTopic/getting_started/visualization/visualize_documents.html#visualize-documents-with-plotly","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"https://​maartengr​.github​.io​/BERTopic​/getting​_started​/visualization​/visualize​_documents​.html​#visualize​-documents​-with​-plotly","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"xpOfCXUODd"}],"urlSource":"https://maartengr.github.io/BERTopic/getting_started/visualization/visualize_documents.html#visualize-documents-with-plotly","key":"IDoA1hT1GB"}],"key":"CroyIccRnK"}],"key":"NVgM07h8cM"},{"type":"listItem","spread":true,"position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"paragraph","children":[{"type":"link","url":"https://maartengr.github.io/BERTopic/getting_started/visualization/visualize_topics.html","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"text","value":"https://​maartengr​.github​.io​/BERTopic​/getting​_started​/visualization​/visualize​_topics​.html","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"iikrGxJict"}],"urlSource":"https://maartengr.github.io/BERTopic/getting_started/visualization/visualize_topics.html","key":"ZHwQWLFqkH"}],"key":"hoc2SrROCc"}],"key":"tr8jgfneog"}],"key":"dJZLDdNlVA"}],"key":"tKkwPRDQvf"}],"key":"fxSeov6AjU"}],"key":"MIafS49t28"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"import spacy\nfrom tqdm import tqdm\nfrom collections import Counter\nimport pandas as pd\n\n# imports\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nplt.style.use('seaborn-v0_8-dark') \n\nsou = pd.read_csv('data/SOTU.csv')\nnlp = spacy.load(\"en_core_web_sm\")","key":"RUHjoGVidj"},{"type":"output","id":"4i7kJTIWxtauD2Y7QSax4","data":[],"key":"hy9SgZu1i4"}],"key":"YodmfgM9kT"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"from spacy import displacy\nfrom bertopic import BERTopic\nfrom gensim.corpora import Dictionary\nfrom gensim.models import LdaModel\nfrom sklearn.feature_extraction.text import CountVectorizer\nimport pyLDAvis\nimport pyLDAvis.gensim_models","key":"svlJfZ3VAj"},{"type":"output","id":"WvkRfRN3JusJ5M48qQZDI","data":[],"key":"uUBJDhF0Qb"}],"key":"QcHZRdA9qN"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"LDA","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"M708vQdGBw"}],"identifier":"lda","label":"LDA","html_id":"lda","implicit":true,"key":"UoiuOQVsnV"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":3,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Train an LDA model with 18 topics","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"d8nqEl82V4"}],"key":"WBPny9bsHu"}],"key":"UzDsUike4P"},{"type":"listItem","spread":true,"position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Output the top 10 words for each topic.","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"ozw6dmGHuo"}],"key":"QV0AgWmGap"}],"key":"c4IVOxyCSj"},{"type":"listItem","spread":true,"position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Output the topic distribution for the first speech","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"WlgBy0sJNL"}],"key":"zd15YG5Ctf"}],"key":"ztfC6HNn6F"},{"type":"listItem","spread":true,"position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Make a visualization","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"Ogw0tiVJ95"}],"key":"IQwe5u7cZp"}],"key":"mb82uXz112"}],"key":"VF6WwmV9vI"}],"key":"QLpJAmqYO5"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"You may use the next two cells to process the data.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"C4h1xmPhoz"}],"key":"ydrlDY7sI5"}],"key":"mbU7EtfPIg"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"def preprocess_text(text): \n    doc = nlp(text) \n    return [token.lemma_.lower() for token in doc if not token.is_stop and not token.is_punct and not token.is_space and len(token.lemma_) \u003e 3]","key":"PYb0gUBvtX"},{"type":"output","id":"rBzEsXBs7JZfRYzVqrUNo","data":[],"key":"oAuD6BPMVS"}],"key":"NAcd3pGvo7"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Process all texts - note this takes ~ 5 minutes to run\nprocessed_docs = sou['Text'].apply(preprocess_text)","key":"ft3gONNYy5"},{"type":"output","id":"FdajRZaOgVZYJDGM5-Qte","data":[],"key":"Qhv5jIR7jw"}],"key":"ljwXBkvbss"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"To train an LDA model, use the LdaModel function that we imported a couple of cells back. The last resource linked under the LDA section is especially useful for walking through the steps we have below. ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"yZJRvcoIsB"},{"type":"emphasis","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Note: one of the arguments to the LdaModel function is ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"KshfDqTCri"},{"type":"inlineCode","value":"random_state","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"dvSjqi63XM"},{"type":"text","value":" which specifies the random seed for reproducibility. Please set yours to 42. Further, the last resource provided uses ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"t8AvsskftJ"},{"type":"inlineCode","value":"LdaMulticore","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"D5bMEvyjLZ"},{"type":"text","value":" which is essentially a parallelizable version of our function ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"rmbzAvC0ty"},{"type":"inlineCode","value":"LdaModel","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"am0E1DTkRF"},{"type":"text","value":". Use ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"MJ5pPmmrT4"},{"type":"inlineCode","value":"LdaModel","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"H1KX71MAXC"},{"type":"text","value":" instead, but the usage will be similar, except you can ignore the ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"TEVcY6DIAy"},{"type":"inlineCode","value":"iterations","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"ecQa84RmpT"},{"type":"text","value":" and ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"sruNJOO4rq"},{"type":"inlineCode","value":"workers","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"OdA14l47z6"},{"type":"text","value":" arguments..","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"bzBmJILp71"}],"key":"gaCunM054Y"},{"type":"text","value":".","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"t2ioDraFgo"}],"key":"iwSax5cjrr"}],"key":"iXsT97Kk9o"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Build dictionary from processed_docs, which is a list of tokens extracted from our speeches\n\nsou['tokens'] = processed_docs\n#Gensim Dictionary object maps each word to their unique ID:\ndictionary = Dictionary(sou['tokens'])\n#print(dictionary.token2id)\n#dictionary.filter_extremes(no_below=5, no_above=0.5, keep_n=1000)\n\n#create sparse vector (i, j) where i is dictionary id and j is number of occurences of that distinct word (?)\ncorpus = [dictionary.doc2bow(doc) for doc in sou['tokens']]","key":"S8YL59JEiZ"},{"type":"output","id":"YjdWy1ao7o6x48GdXUXs_","data":[],"key":"zwPBdyz7ch"}],"key":"EeSdls9YYT"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# train LDA model with 18 topics\nlda_model = LdaModel(corpus=corpus, id2word=dictionary, num_topics=18, random_state=42, passes=10)","key":"zGbNgTQPRJ"},{"type":"output","id":"qQbuIV5ItDQwGKuGGVJui","data":[],"key":"HiuvunQvj9"}],"key":"WoAZuhyAKA"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# print the top 10 words for each topic\nlda_model.print_topics(-1)","key":"zRS7U0okHU"},{"type":"output","id":"_5oqISAsrt_cYpBtjXuhB","data":[],"key":"nefQvM7O5l"}],"key":"ksXCNlxWzk"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# print the topic distribution for the first speech\nsou['Text'][0]\nlda_model[corpus][0]","key":"DpO9kpOwi6"},{"type":"output","id":"Kcd4P20F03xnRgT_yNCaA","data":[],"key":"uFHcNR5T9e"}],"key":"njUMumtKtS"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"The first speech is 99% belonging to topic 2!","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"SDA2jQf9fI"}],"key":"HuTuZTcVXU"}],"key":"GmOi6bh1KH"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# make a visualization using pyLDAvis\npyLDAvis.enable_notebook()\n\nlda_display = pyLDAvis.gensim_models.prepare(lda_model, corpus, dictionary)\npyLDAvis.display(lda_display)\n","key":"HZtdw93sNU"},{"type":"output","id":"EMVb3916xHFqkDimbVPjq","data":[],"key":"JbZHeTp0Bv"}],"key":"sLnNxelbmL"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"#save to outputs\npyLDAvis.save_html(lda_display, 'outputs/lda_topics.html')","key":"LSn4bOcn2Q"},{"type":"output","id":"zJfbTd7XTx3HEHIjlyDjW","data":[],"key":"KrR88AWkQ6"}],"key":"pkG8YMnZOz"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"BERTopic","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"ZBDWaeVIQe"}],"identifier":"bertopic","label":"BERTopic","html_id":"bertopic","implicit":true,"key":"urVY9DnReI"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":3,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Train a BERTopic model with a ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"HQgcMTBYsr"},{"type":"inlineCode","value":"min_topic_size","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"kglPRwkW2F"},{"type":"text","value":" of 3 ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"mCm9IVsgpS"},{"type":"emphasis","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Hint: use ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"p9UDckEOaa"},{"type":"inlineCode","value":"BERTopic","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"VUL3wgVhcA"},{"type":"text","value":" to instantiate the model and specify ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"qOWKUqBj4r"},{"type":"inlineCode","value":"min_topic_size","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"D44wtrR1Ob"},{"type":"text","value":" in here. Actually fit the model using ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"WB7ljVBBVC"},{"type":"inlineCode","value":"fit_transform","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"bPzSzHXjoN"},{"type":"text","value":", which ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"BFkqtA3qpJ"},{"type":"inlineCode","value":"docs","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"qEI6uJ33Zc"},{"type":"text","value":" passed into this.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"m8tkGRvXS9"}],"key":"JhkJpbzngI"}],"key":"kBjdZeZfZf"}],"key":"Uf8z3YQ83k"},{"type":"listItem","spread":true,"position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Output the top 10 words for each topic.","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"OC2lx30jya"}],"key":"OWDqR6cgus"}],"key":"kiB41hjNKW"},{"type":"listItem","spread":true,"position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Output the topic distribution for the first speech","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"TIT089uvRT"}],"key":"BOfL888FpG"}],"key":"FAZZwEEJ90"},{"type":"listItem","spread":true,"position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Make a visualization of the topics (see topic_model.visualize_topics())","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"DH9deqOac2"}],"key":"T7lnvRSj41"}],"key":"KZaDWnEBxV"}],"key":"pMigvliV9M"}],"key":"JBImfk3bIX"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"from bertopic import BERTopic\nfrom sklearn.datasets import fetch_20newsgroups\nfrom sklearn.feature_extraction.text import CountVectorizer","key":"AwB8u01cTH"},{"type":"output","id":"DowdRXVRyRMPw2cg9rATF","data":[],"key":"H6vinjdr3A"}],"key":"gdd7PiqKET"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"docs = sou['Text'].to_list()","key":"QfxZceN5Ct"},{"type":"output","id":"KE68ALN-VHCnbEXQ8zm7L","data":[],"key":"qE64qSJ6VO"}],"key":"buCwiuqhTI"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# train the model - this takes about 30 seconds\ntopic_model = BERTopic(min_topic_size=3)\ntopics, probs = topic_model.fit_transform(docs)\n\n\n# remove stop words from the topics (Hint: use CountVectorizer and then .update_topics on topic_model)\nvectorizer_model = CountVectorizer(stop_words=\"english\")\ntopic_model.update_topics(docs, vectorizer_model=vectorizer_model) ","key":"vNK4P63UYA"},{"type":"output","id":"_znWn5buGXPTtCsi6SvRB","data":[],"key":"NFCywBFO4o"}],"key":"vuAQFo2W7V"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# output the top 10 words for each topic - hint see get_topic_info\ntopic_model.get_topic_info()['Representation']","key":"nU6aBg6AQq"},{"type":"output","id":"UVb9UiBLCqwBCgoXX9FdH","data":[],"key":"bczx4MF4dU"}],"key":"YTP3hvnzEt"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# output the topic distribution for the first speech\ntopic_distr, _ = topic_model.approximate_distribution(docs)\nfirst_speech_viz = topic_model.visualize_distribution(topic_distr[1])\n\n#save first speech topic distribution to outputs\nfirst_speech_viz.write_html(\"outputs/BERTopic_first_speech_viz.html\")\nfirst_speech_viz","key":"EPcxjkn93T"},{"type":"output","id":"2DibCoVs3q848AO6dVRuj","data":[],"key":"PfHLZ0YJJG"}],"key":"XtQf0PhX4j"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# run this cell to visualize the topics\nviz_topics = topic_model.visualize_topics()\n\n#save topic visualizations to output\nviz_topics.write_html(\"outputs/BERTopic_topics_viz.html\")\nviz_topics","key":"ikBxGsZdh0"},{"type":"output","id":"GR3Q7KRl7KK_c3T2h8hei","data":[],"key":"vLoKOhRKMV"}],"key":"FnTeKeanr4"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Discussion and Reflections","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"IwrusGnYoz"}],"identifier":"discussion-and-reflections","label":"Discussion and Reflections","html_id":"discussion-and-reflections","implicit":true,"key":"DwyU2ZrfD2"}],"key":"sGqCJOdZSs"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"The topic distribution across the two dimensional PCA is notably different for the LDA (bag of words) and BERTopic (semantic similarity) approaches. The LDA distribution appears to have larger clusters on the right quadrant of the analyses, with significantly smaller clusters on the left quadrant. On the other hand, the BERTopic distributions land in each quadrant of the PCA grid, with more even distribution between each in terms of cluster size. This demonstrates how the two approaches use different attributes of the speeches and different algorithms to conclude topic summaries and distributions.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Ye2ZhjstcR"}],"key":"Jm7BXdjGwi"}],"key":"CxLf472iyI"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Part 4: Choose your own advecnture! (7 Points; Optional for Extra Credit)","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"cAac40pTET"}],"identifier":"part-4-choose-your-own-advecnture-7-points-optional-for-extra-credit","label":"Part 4: Choose your own advecnture! (7 Points; Optional for Extra Credit)","html_id":"part-4-choose-your-own-advecnture-7-points-optional-for-extra-credit","implicit":true,"key":"e3s9JGhb9l"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"This section is open ended and your chance to explare any advanced analysis. Please perform any additional analysis you find interesting! Suggested analyses (only do one max):","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"VzrrX9RnRx"}],"key":"wkNJoSoWiC"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":5,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Topic evolution over time - see ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"xDXbhISSMN"},{"type":"link","url":"https://maartengr.github.io/BERTopic/getting_started/topicsovertime/topicsovertime.html#visualization","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"https://​maartengr​.github​.io​/BERTopic​/getting​_started​/topicsovertime​/topicsovertime​.html​#visualization","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"ZCAasqdYUB"}],"urlSource":"https://maartengr.github.io/BERTopic/getting_started/topicsovertime/topicsovertime.html#visualization","key":"o9Gqm1ygYv"}],"key":"knuP2ra5pj"}],"key":"n2McGMxZln"},{"type":"listItem","spread":true,"position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Word frequency over time - does the frequency of certain words change over time","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"SlCPM1xgC5"}],"key":"K0e1rjT66I"}],"key":"rEA1BUzJee"},{"type":"listItem","spread":true,"position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Semantic similarity - investigate similarity within and between presidents or time periods. For example, similarity between one presidents speeches, e.g. are all of Biden’s speeches similar to each other? How similar are they to Trump’s speeches? Are speeches from the 2000s more similar to each other than speeches in the 1800s? Which two presidents have the most similar speeches? See ","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"J5itlzqDYz"},{"type":"link","url":"https://spacy.io/usage/linguistic-features#vectors-similarity","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"https://​spacy​.io​/usage​/linguistic​-features​#vectors​-similarity","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"Y1LXzRjKDH"}],"urlSource":"https://spacy.io/usage/linguistic-features#vectors-similarity","key":"neBRsX5Iat"}],"key":"htfB9IKYHM"}],"key":"M4Lw6CuXTT"},{"type":"listItem","spread":true,"position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Named Entity Recognition - which entity types are most common in speeches? What are the most common words for each entity type - see ","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"xZDob79qi9"},{"type":"link","url":"https://spacy.io/usage/linguistic-features#named-entities","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"text","value":"https://​spacy​.io​/usage​/linguistic​-features​#named​-entities","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"IYa8UWUTfN"}],"urlSource":"https://spacy.io/usage/linguistic-features#named-entities","key":"iyPsyKbdgs"}],"key":"X6VQiCamVt"}],"key":"k7G4w7MwDi"},{"type":"listItem","spread":true,"position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Classification - can you build a classifier to detect democratic versus republican state of the union speeches from 1980-2024 - see ","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"iN37bEM9FD"},{"type":"link","url":"https://scikit-learn.org/stable/auto_examples/text/plot_document_classification_20newsgroups.html#sphx-glr-auto-examples-text-plot-document-classification-20newsgroups-py","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"https://​scikit​-learn​.org​/stable​/auto​_examples​/text​/plot​_document​_classification​_20newsgroups​.html​#sphx​-glr​-auto​-examples​-text​-plot​-document​-classification​-20newsgroups​-py","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"nbQnow0PEh"}],"urlSource":"https://scikit-learn.org/stable/auto_examples/text/plot_document_classification_20newsgroups.html#sphx-glr-auto-examples-text-plot-document-classification-20newsgroups-py","key":"fVTmEl9fXC"}],"key":"IJC5iTwdKd"}],"key":"oCV7koyXO5"}],"key":"SI7cJ47czi"}],"key":"l1sDZ5Jp8y"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Word frequency over time - does the frequency of certain words change over time","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"kBsaRBTaUM"}],"identifier":"word-frequency-over-time-does-the-frequency-of-certain-words-change-over-time","label":"Word frequency over time - does the frequency of certain words change over time","html_id":"word-frequency-over-time-does-the-frequency-of-certain-words-change-over-time","implicit":true,"key":"hGBEHt8UlG"}],"key":"gQnemwZUVk"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"import re\n\n# Define words we think are important in this case\nwords = [\"freedom\", \"economy\", \"security\", \"health\"]\n\n\ndef count_word(text, word):\n    \"\"\"\n    RegEx Method to find variations of the word (case insensitive)\n    \"\"\"\n    pattern = r'\\b' + re.escape(word) + r'\\b'\n    return len(re.findall(pattern, text, flags=re.IGNORECASE))\n\n\n# Iterate through every word and get the raw count per year and then scale it\nfor w in words:\n    raw_col = f\"freq_{w}\"\n    rel_col = f\"rel_freq_{w}\"\n    sou[raw_col] = sou[\"Text\"].apply(lambda x: count_word(x, w))\n    sou[rel_col] = sou[raw_col] / sou[\"Word Count\"] * 1000\n\n\n# Sort the values every year\nsou_sorted = sou.sort_values(\"Year\").reset_index(drop=True)\n\n# Iterate through the words and fit a rolling average\nfor w in words:\n    col = f\"rel_freq_{w}\"\n    sou_sorted[col + \"_smooth\"] = (\n        sou_sorted[col].rolling(window=10, min_periods=3).mean()\n    )\n\nplt.figure(figsize=(12, 6))\n\n# Plot for the respective years\nfor w in words:\n    plt.plot(\n        sou_sorted[\"Year\"],\n        sou_sorted[f\"rel_freq_{w}_smooth\"],\n        label=w\n    )\n\nplt.title(\"Word Frequency Over Time (10-year rolling average)\")\nplt.xlabel(\"Year\")\nplt.ylabel(\"Relative Frequency (per 1000 words)\")\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.show()","key":"ASHvRMTJgQ"},{"type":"output","id":"Wl-n42C6sAGyzMYOR1Qvi","data":[],"key":"zo5X8V84B4"}],"key":"q852UZkEEr"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":4,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Freedom","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"K652sZaLT2"}],"identifier":"freedom","label":"Freedom","html_id":"freedom","implicit":true,"key":"SV7aUOMDrL"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Mentions of freedom stay low throughout the 1800s, then gradually increase in the early 20th century. The term spikes sharply during the Cold War (1970s–1990s), when U.S. presidents frequently framed politics in ideological terms. Another noticeable peak appears in the early 2000s during the post-9/11 era, when “freedom” became central to national messaging. Through time, “freedom” becomes a major rhetorical theme primarily in the modern era.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"y5mcgfXiTu"}],"key":"sxz6JBwBqF"},{"type":"heading","depth":4,"position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"Economy","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"VHg39tgN2a"}],"identifier":"economy","label":"Economy","html_id":"economy","implicit":true,"key":"XFVGVtAgnx"},{"type":"paragraph","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"The word economy remains rarely used before 1900, but rises significantly during major economic crises. There are clear peaks during the Great Depression (1930s), post-WWII recovery, the stagflation era (1970s), and again around the Great Recession (2008–2010). The pattern reflects how presidents address economic instability directly in their State of the Union speeches.","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"dt1mNrczYa"}],"key":"iN3B0KQwMb"},{"type":"heading","depth":4,"position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"Security","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"XqIzeSoXDY"}],"identifier":"security","label":"Security","html_id":"security","implicit":true,"key":"QuKqMEodQZ"},{"type":"paragraph","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"text","value":"Security shows the strongest spikes of any word. Usage jumps dramatically during World War II, peaks again throughout the Cold War, and rises once more after 2001 in response to terrorism and national security concerns. This term closely tracks periods when the nation faces real or perceived threats, making it the most crisis-driven word in the group.","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"DCHInufkjL"}],"key":"tXQxTj8NdG"},{"type":"heading","depth":4,"position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"children":[{"type":"text","value":"Health","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"pFvUkkCtAY"}],"identifier":"health","label":"Health","html_id":"health","implicit":true,"key":"xSEfF1Grzl"},{"type":"paragraph","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"children":[{"type":"text","value":"Mentions of health are almost nonexistent before the 20th century. Use rises steadily as the federal government becomes more involved in public health policy—especially around the creation of Medicare and Medicaid (1960s), health reform debates in the 1990s, the Affordable Care Act period (2009–2015), and again around 2020 during the COVID-19 pandemic. “Health” is the newest major theme in modern SOTU speeches.","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"xlf8f9TdTL"}],"key":"G3Xu2JABtH"},{"type":"heading","depth":4,"position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"children":[{"type":"text","value":"Overall Summary","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"key":"C7fWx9AXCx"}],"identifier":"overall-summary","label":"Overall Summary","html_id":"overall-summary","implicit":true,"key":"Wbe2aWFpFS"},{"type":"paragraph","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"children":[{"type":"text","value":"Across all four words, usage stays low before 1900 and rises sharply in the modern era as speeches become more policy-focused. The trends reveal how presidential priorities evolve: “security” peaks during wars and threats, “economy” during financial crises, “freedom” during ideological conflicts, and “health” during healthcare policy shifts and pandemics. Together, these patterns highlight how State of the Union language reflects broad historical changes in national concerns.","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"key":"bzPsgxdhev"}],"key":"SLTCmrfmSp"}],"key":"m0b6j1gAtO"}],"key":"xSN2dnIAi6"},"references":{"cite":{"order":[],"data":{}}},"footer":{"navigation":{"prev":{"title":"Part 4","url":"/nlp-p04","group":"Stat159 Project 2 - Reproducibility in Natural Language Processing"},"next":{"title":"Project 2: Reproducibility in Natural Langauge Processing","url":"/project-description","group":"Stat159 Project 2 - Reproducibility in Natural Language Processing"}}},"domain":"http://localhost:3000"},"project":{"title":"Stat159 Project 2 - Reproducibility in Natural Language Processing","authors":[{"nameParsed":{"literal":"Reily Fairchild","given":"Reily","family":"Fairchild"},"name":"Reily Fairchild","affiliations":["UC Berkeley"],"id":"contributors-myst-generated-uid-0"},{"nameParsed":{"literal":"Atiila Joselyn Birah Kharobo","given":"Atiila Joselyn Birah","family":"Kharobo"},"name":"Atiila Joselyn Birah Kharobo","affiliations":["UC Berkeley"],"id":"contributors-myst-generated-uid-1"},{"nameParsed":{"literal":"Jordan Elizabeth Collins","given":"Jordan Elizabeth","family":"Collins"},"name":"Jordan Elizabeth Collins","affiliations":["UC Berkeley"],"id":"contributors-myst-generated-uid-2"},{"nameParsed":{"literal":"Aditya Jagannadha Sai Mangalampalli","given":"Aditya Jagannadha Sai","family":"Mangalampalli"},"name":"Aditya Jagannadha Sai Mangalampalli","affiliations":["UC Berkeley"],"id":"contributors-myst-generated-uid-3"}],"github":"https://github.com/UCB-stat-159-f25/proj02-group7","affiliations":[{"id":"UC Berkeley","name":"UC Berkeley"}],"id":"a74ecdef-c9eb-4683-b555-417faf7e975c","toc":[{"file":"index.md"},{"file":"contributions.md"},{"file":"nlp-P01.ipynb"},{"file":"nlp-P02.ipynb"},{"file":"nlp-P03.ipynb"},{"file":"nlp-P04.ipynb"},{"file":"proj02-nlp.ipynb"},{"file":"project-description.md"}],"thumbnail":"/user/jcollins36855/myst-build/proj02-group7/build/b77199e99a54e59b2e3c037c2cc90f21.svg","exports":[],"bibliography":[],"index":"index","pages":[{"slug":"contributions","title":"Contributions","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"nlp-p01","title":"Project 2: Reproducibility in Natural Language Processing","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"nlp-p02","title":"Part 2: Simple Text Processing - Tokenization, Lemmatization, Word Frequency, Vectorization (20 pts)","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"nlp-p03","title":"Part 3: Advanced Text Processing - LDA and BERTopic Topic Modeling (20 pts)","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"nlp-p04","title":"Part 4","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"proj02-nlp","title":"Project 2: Reproducibility in Natural Language Processing","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"project-description","title":"Project 2: Reproducibility in Natural Langauge Processing","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1}]}}},"actionData":null,"errors":null},"future":{"unstable_dev":false,"unstable_postcss":false,"unstable_tailwind":false,"v2_errorBoundary":true,"v2_headers":true,"v2_meta":true,"v2_normalizeFormMethod":true,"v2_routeConvention":true}};</script><script type="module" async="">import "/user/jcollins36855/myst-build/proj02-group7/build/manifest-3481E987.js";
import * as route0 from "/user/jcollins36855/myst-build/proj02-group7/build/root-7TUVC4ZT.js";
import * as route1 from "/user/jcollins36855/myst-build/proj02-group7/build/routes/$-P6PGXPYX.js";
window.__remixRouteModules = {"root":route0,"routes/$":route1};

import("/user/jcollins36855/myst-build/proj02-group7/build/entry.client-UNPC4GT3.js");</script></body></html>